{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35542b5a2e494ecf840601f52695953f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42e44c009dcd476184ea6fcf25eba491",
              "IPY_MODEL_21111e31033b48508a7351557744270c",
              "IPY_MODEL_6ee4dcfbe4974a9298a844892046f38b"
            ],
            "layout": "IPY_MODEL_20bc612578d0414d9b602c1132163ae7"
          }
        },
        "42e44c009dcd476184ea6fcf25eba491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7f4990110b4c5b9f95ac551ddebd99",
            "placeholder": "​",
            "style": "IPY_MODEL_97c2c0c512704d87bcd440273be90986",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "21111e31033b48508a7351557744270c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11663d5b5ece4d94bfbb5b0125129935",
            "max": 564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d65dbd9a12b44ae96b8446751509944",
            "value": 564
          }
        },
        "6ee4dcfbe4974a9298a844892046f38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dfea964693e4a22a318cfbb4fcce4fd",
            "placeholder": "​",
            "style": "IPY_MODEL_fd299fb1d29840738c828a038c2a8f3c",
            "value": " 564/564 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "20bc612578d0414d9b602c1132163ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7f4990110b4c5b9f95ac551ddebd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c2c0c512704d87bcd440273be90986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11663d5b5ece4d94bfbb5b0125129935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d65dbd9a12b44ae96b8446751509944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dfea964693e4a22a318cfbb4fcce4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd299fb1d29840738c828a038c2a8f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f820473a11f444fa165d33b175917d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12248aba4f624a86a731ec15166a96bf",
              "IPY_MODEL_cf4ce81b42fa444c8ae31fd4a18f3789",
              "IPY_MODEL_6f4476ea5ad4434ab8c533e273d7db85"
            ],
            "layout": "IPY_MODEL_807e418362154278be8dd803ee7ed183"
          }
        },
        "12248aba4f624a86a731ec15166a96bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d62e0f35724e53ac295a611089f890",
            "placeholder": "​",
            "style": "IPY_MODEL_69ad0b6987a74eab8548691d1ecc5d1a",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "cf4ce81b42fa444c8ae31fd4a18f3789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417ea99c20844dc39e845627f0c3f2de",
            "max": 4852054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b55dfcd6bb94753b6c14a34242667f0",
            "value": 4852054
          }
        },
        "6f4476ea5ad4434ab8c533e273d7db85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95806565414f45da971f244dc06d9383",
            "placeholder": "​",
            "style": "IPY_MODEL_6257b1cadc0d44c28f92570828ddf399",
            "value": " 4.85M/4.85M [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "807e418362154278be8dd803ee7ed183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d62e0f35724e53ac295a611089f890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ad0b6987a74eab8548691d1ecc5d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417ea99c20844dc39e845627f0c3f2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b55dfcd6bb94753b6c14a34242667f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95806565414f45da971f244dc06d9383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6257b1cadc0d44c28f92570828ddf399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ec55f44651543d1a7ea1f4f9c0679a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12f9b1dba6d94f42ac137ab515c8c4b5",
              "IPY_MODEL_eb0b44457f404c74a6f8b3d7b6c9123f",
              "IPY_MODEL_39fd115b98da4f639d9431f50a5562cf"
            ],
            "layout": "IPY_MODEL_9f07ad75cee948aeaa89428148fa0759"
          }
        },
        "12f9b1dba6d94f42ac137ab515c8c4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_168c1ce83bf646e2849d6bcc26e4f061",
            "placeholder": "​",
            "style": "IPY_MODEL_f1b04db7d5d941a5a7c9b01b66dd0749",
            "value": "tokenizer.json: 100%"
          }
        },
        "eb0b44457f404c74a6f8b3d7b6c9123f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e98b80862744e795ce6287dfa56602",
            "max": 17331176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a7bd953f5d45cf87035d3b6429e16b",
            "value": 17331176
          }
        },
        "39fd115b98da4f639d9431f50a5562cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16361e0dec440e8963927761dfa053b",
            "placeholder": "​",
            "style": "IPY_MODEL_e07f13b148754680bd8132630734fb88",
            "value": " 17.3M/17.3M [00:00&lt;00:00, 52.6MB/s]"
          }
        },
        "9f07ad75cee948aeaa89428148fa0759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168c1ce83bf646e2849d6bcc26e4f061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b04db7d5d941a5a7c9b01b66dd0749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e98b80862744e795ce6287dfa56602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a7bd953f5d45cf87035d3b6429e16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d16361e0dec440e8963927761dfa053b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07f13b148754680bd8132630734fb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af1f0c4db7a49c7b0e1ac80c19c13a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d60d22a629f0463c88e525f99d3ed610",
              "IPY_MODEL_5e3116aaca904f61a57528e253a48eb9",
              "IPY_MODEL_285042db78444234938d0c65a9dcf310"
            ],
            "layout": "IPY_MODEL_617ffa1a246645358954c51010390e0e"
          }
        },
        "d60d22a629f0463c88e525f99d3ed610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c1173f27f14b08ad09fcda7a279085",
            "placeholder": "​",
            "style": "IPY_MODEL_f64d282188674bada3bf2867a19da1d9",
            "value": "special_tokens_map.json: "
          }
        },
        "5e3116aaca904f61a57528e253a48eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe525c8919234251bb84b8f054ad1296",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e3be36b2a634232878db11f8d3bd9b9",
            "value": 1
          }
        },
        "285042db78444234938d0c65a9dcf310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e22a264ad74e05bc192d4dd4719a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_10e3a37ee06440dda627e5b06c8fe598",
            "value": " 3.55k/? [00:00&lt;00:00, 83.0kB/s]"
          }
        },
        "617ffa1a246645358954c51010390e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c1173f27f14b08ad09fcda7a279085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64d282188674bada3bf2867a19da1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe525c8919234251bb84b8f054ad1296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0e3be36b2a634232878db11f8d3bd9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31e22a264ad74e05bc192d4dd4719a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e3a37ee06440dda627e5b06c8fe598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3dc8b76e90e4785ab2fa9300928e548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffd990fd68ed4b9381f346fb93e14694",
              "IPY_MODEL_ff576084e38441dabae17691c0efe928",
              "IPY_MODEL_8f5834ac126445f8a34ae6ea00fea9c6"
            ],
            "layout": "IPY_MODEL_bef8cc7055db40edb2549bc0550686e3"
          }
        },
        "ffd990fd68ed4b9381f346fb93e14694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_861b24b3a62c4a4c99dc447d22c0d5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a1c8fbff745d4b8db5058b0e4fac921b",
            "value": "config.json: 100%"
          }
        },
        "ff576084e38441dabae17691c0efe928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc4d5911f944f0eac505634468c0da7",
            "max": 846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f982732f5f1c4069a78e5f72c195a646",
            "value": 846
          }
        },
        "8f5834ac126445f8a34ae6ea00fea9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8d7937fe214a84a7983260914382aa",
            "placeholder": "​",
            "style": "IPY_MODEL_10fdc77602e943d7b3da6c2b1ef918b6",
            "value": " 846/846 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "bef8cc7055db40edb2549bc0550686e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861b24b3a62c4a4c99dc447d22c0d5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c8fbff745d4b8db5058b0e4fac921b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc4d5911f944f0eac505634468c0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f982732f5f1c4069a78e5f72c195a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c8d7937fe214a84a7983260914382aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10fdc77602e943d7b3da6c2b1ef918b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4f07930e6447dc85c33e10339d2f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19820ce362da427da718a1a2729ba985",
              "IPY_MODEL_7ae5ae92692447f6a91aea60459fcc84",
              "IPY_MODEL_8e3e39d823a74653a3f41279f3865d04"
            ],
            "layout": "IPY_MODEL_177fce9354a547c88bb5ebbe569e4181"
          }
        },
        "19820ce362da427da718a1a2729ba985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bca80b1d239416f9179b55115c427fc",
            "placeholder": "​",
            "style": "IPY_MODEL_20a66a17ebed4b0cb0bbec841a1bb6c8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7ae5ae92692447f6a91aea60459fcc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7539a80be334febb302d61c2c24f61b",
            "max": 2460457927,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bd89e9dd3c848759366c87bc3cb2786",
            "value": 2460457927
          }
        },
        "8e3e39d823a74653a3f41279f3865d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b9ed8d479e401fa502cc9c3911bb06",
            "placeholder": "​",
            "style": "IPY_MODEL_656c7c858fd04e64b9e2bb2b07f65b5f",
            "value": " 2.46G/2.46G [00:27&lt;00:00, 131MB/s]"
          }
        },
        "177fce9354a547c88bb5ebbe569e4181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bca80b1d239416f9179b55115c427fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a66a17ebed4b0cb0bbec841a1bb6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7539a80be334febb302d61c2c24f61b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd89e9dd3c848759366c87bc3cb2786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42b9ed8d479e401fa502cc9c3911bb06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656c7c858fd04e64b9e2bb2b07f65b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4791078c1f24931b7cca35e19da0d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c7d7cb8ad9c4ba69660a5e484b0b9be",
              "IPY_MODEL_0d3573736db54af6b78204d8273b3063",
              "IPY_MODEL_0ae13c2e92a54d9dbf96bd80b0dbe4b2"
            ],
            "layout": "IPY_MODEL_024fbfb521b04e2fad5a7a34a81085eb"
          }
        },
        "9c7d7cb8ad9c4ba69660a5e484b0b9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ffef53e9e9475ca7066c7cda34a632",
            "placeholder": "​",
            "style": "IPY_MODEL_042e4de552734e0e885eb2e6eb364e9c",
            "value": "model.safetensors: 100%"
          }
        },
        "0d3573736db54af6b78204d8273b3063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4efd7fb8e644e82967e01d5ec4d18b5",
            "max": 2460355968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d071efc13f28433a95589f733782192b",
            "value": 2460355968
          }
        },
        "0ae13c2e92a54d9dbf96bd80b0dbe4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2c9d5e4b4948a4bd9d754e7f1cf1c7",
            "placeholder": "​",
            "style": "IPY_MODEL_769882f9a3b543ffb4a199b565f4cdaf",
            "value": " 2.46G/2.46G [01:09&lt;00:00, 42.9MB/s]"
          }
        },
        "024fbfb521b04e2fad5a7a34a81085eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ffef53e9e9475ca7066c7cda34a632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "042e4de552734e0e885eb2e6eb364e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4efd7fb8e644e82967e01d5ec4d18b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d071efc13f28433a95589f733782192b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2c9d5e4b4948a4bd9d754e7f1cf1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769882f9a3b543ffb4a199b565f4cdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d6ecb8573d4a649e5f6ded47aede55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b1b66bdf47d4d99af036cc77263c6bc",
              "IPY_MODEL_6f45bf47e54143cba2ba6c5e227472f6",
              "IPY_MODEL_0959bb7330a941c0a5b7ed044413b425"
            ],
            "layout": "IPY_MODEL_55278d257beb474ea080e47973c4f3ec"
          }
        },
        "6b1b66bdf47d4d99af036cc77263c6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b1ee6211a14d839fdcdd18ebe9aeab",
            "placeholder": "​",
            "style": "IPY_MODEL_5faf2a2bb8e748ec88e67c4b804f2ba4",
            "value": "generation_config.json: 100%"
          }
        },
        "6f45bf47e54143cba2ba6c5e227472f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e80cf247cc48dd80c901e176da9ab6",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c4ed9a418df49afbffadfaac270eb64",
            "value": 189
          }
        },
        "0959bb7330a941c0a5b7ed044413b425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4f8108508746279b81b77cc63fa386",
            "placeholder": "​",
            "style": "IPY_MODEL_28bcc1be927e42f8bb2baef9652488b6",
            "value": " 189/189 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "55278d257beb474ea080e47973c4f3ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b1ee6211a14d839fdcdd18ebe9aeab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faf2a2bb8e748ec88e67c4b804f2ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55e80cf247cc48dd80c901e176da9ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4ed9a418df49afbffadfaac270eb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf4f8108508746279b81b77cc63fa386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bcc1be927e42f8bb2baef9652488b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7b89200f6946c7992f9a4ca7529abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8926727c305474db8a58b5fd23e84c1",
              "IPY_MODEL_85b647b3ce284366a062113f447a7d0f",
              "IPY_MODEL_df2248a4a74a4f688411842cbde490f4"
            ],
            "layout": "IPY_MODEL_b7a2d7c37a5247daa6a11a32429a2a48"
          }
        },
        "e8926727c305474db8a58b5fd23e84c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb83646e9387475299adf463ef139059",
            "placeholder": "​",
            "style": "IPY_MODEL_d6cbb9071a2d4ff995a1564771f46ec1",
            "value": "100%"
          }
        },
        "85b647b3ce284366a062113f447a7d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336e0b4b901c4ee0ab4799b6da0dc6b0",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6442c509f81b4f34ad262ceb900d106a",
            "value": 111898327
          }
        },
        "df2248a4a74a4f688411842cbde490f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38830a9b63034f5399380bd31ef1cc54",
            "placeholder": "​",
            "style": "IPY_MODEL_b77c79d38e1b466e88f47d3a4ed953cf",
            "value": " 107M/107M [00:01&lt;00:00, 85.1MB/s]"
          }
        },
        "b7a2d7c37a5247daa6a11a32429a2a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb83646e9387475299adf463ef139059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6cbb9071a2d4ff995a1564771f46ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336e0b4b901c4ee0ab4799b6da0dc6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6442c509f81b4f34ad262ceb900d106a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38830a9b63034f5399380bd31ef1cc54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77c79d38e1b466e88f47d3a4ed953cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Implement basic speech recognition using Whisper\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q openai-whisper torch torchaudio transformers matplotlib ipython\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import whisper\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "import IPython\n",
        "import IPython.display as ipd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Version information\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")\n",
        "print(f\"Whisper version: {whisper.__version__}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.random.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Configure matplotlib for better plots\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SygirzSd73tF",
        "outputId": "7f9cf772-096d-4439-eb87-d1af7defb0f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "PyTorch version: 2.6.0+cu124\n",
            "Torchaudio version: 2.6.0+cu124\n",
            "Whisper version: 20250625\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSjs7WrX7l-X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper model\n",
        "# Try different model sizes and compare results\n",
        "model_size = \"base\"  # You can experiment with: tiny, base, small, medium, large\n",
        "model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "print(f\"Loaded Whisper {model_size} model\")\n",
        "print(f\"Model device: {device}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Display model architecture overview\n",
        "print(f\"\\nWhisper {model_size} Architecture:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYt4nWZf7yL1",
        "outputId": "23ec3472-1cb6-4e4c-dfd1-5c2c4c691a72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 74.0MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Whisper base model\n",
            "Model device: cpu\n",
            "Model parameters: 71,825,920\n",
            "\n",
            "Whisper base Architecture:\n",
            "Whisper(\n",
            "  (encoder): AudioEncoder(\n",
            "    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (blocks): ModuleList(\n",
            "      (0-5): 6 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TextDecoder(\n",
            "    (token_embedding): Embedding(51865, 512)\n",
            "    (blocks): ModuleList(\n",
            "      (0-5): 6 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (cross_attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7dRTeaK89SHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers if not already available\n",
        "# !pip install transformers torch sentencepiece\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n",
        "\n",
        "def setup_translation_models(model_name=\"facebook/nllb-200-distilled-600M\"):\n",
        "    \"\"\"\n",
        "    Set up NLLB translation models for multiple language pairs\n",
        "\n",
        "    Args:\n",
        "        model_name: NLLB model variant to use\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of translation pipelines\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"🔧 Setting up NLLB Translation Models:\")\n",
        "    print(f\"   Model: {model_name}\")\n",
        "    print(f\"   Loading tokenizer and model...\")\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "        print(f\"   ✅ Model loaded successfully\")\n",
        "        print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "        # Move to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            model = model.to(\"cuda\")\n",
        "            print(f\"   📱 Model moved to GPU\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Define common language pairs\n",
        "    language_pairs = {\n",
        "        'en_to_fr': {'src': 'eng_Latn', 'tgt': 'fra_Latn', 'name': 'English → French'},\n",
        "        'en_to_es': {'src': 'eng_Latn', 'tgt': 'spa_Latn', 'name': 'English → Spanish'},\n",
        "        'en_to_de': {'src': 'eng_Latn', 'tgt': 'deu_Latn', 'name': 'English → German'},\n",
        "        'en_to_zh': {'src': 'eng_Latn', 'tgt': 'zho_Hans', 'name': 'English → Chinese (Simplified)'},\n",
        "        'en_to_ja': {'src': 'eng_Latn', 'tgt': 'jpn_Jpan', 'name': 'English → Japanese'},\n",
        "        'en_to_ar': {'src': 'eng_Latn', 'tgt': 'arb_Arab', 'name': 'English → Arabic'},\n",
        "        'en_to_hi': {'src': 'eng_Latn', 'tgt': 'hin_Deva', 'name': 'English → Hindi'},\n",
        "        'en_to_ru': {'src': 'eng_Latn', 'tgt': 'rus_Cyrl', 'name': 'English → Russian'},\n",
        "    }\n",
        "\n",
        "    # Create translation pipelines\n",
        "    translators = {}\n",
        "\n",
        "    print(f\"\\n🌍 Creating translation pipelines:\")\n",
        "    for pair_id, config in language_pairs.items():\n",
        "        try:\n",
        "            translator = pipeline(\n",
        "                'translation',\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                src_lang=config['src'],\n",
        "                tgt_lang=config['tgt'],\n",
        "                max_length=512,\n",
        "                device=0 if torch.cuda.is_available() else -1\n",
        "            )\n",
        "\n",
        "            translators[pair_id] = {\n",
        "                'pipeline': translator,\n",
        "                'config': config\n",
        "            }\n",
        "\n",
        "            print(f\"   ✅ {config['name']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Failed to create {config['name']}: {e}\")\n",
        "\n",
        "    print(f\"\\n🎉 Created {len(translators)} translation pipelines\")\n",
        "    return translators\n",
        "\n",
        "# Set up translation models\n",
        "print(\"Initializing translation models...\")\n",
        "translation_models = setup_translation_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743,
          "referenced_widgets": [
            "35542b5a2e494ecf840601f52695953f",
            "42e44c009dcd476184ea6fcf25eba491",
            "21111e31033b48508a7351557744270c",
            "6ee4dcfbe4974a9298a844892046f38b",
            "20bc612578d0414d9b602c1132163ae7",
            "6c7f4990110b4c5b9f95ac551ddebd99",
            "97c2c0c512704d87bcd440273be90986",
            "11663d5b5ece4d94bfbb5b0125129935",
            "9d65dbd9a12b44ae96b8446751509944",
            "0dfea964693e4a22a318cfbb4fcce4fd",
            "fd299fb1d29840738c828a038c2a8f3c",
            "0f820473a11f444fa165d33b175917d1",
            "12248aba4f624a86a731ec15166a96bf",
            "cf4ce81b42fa444c8ae31fd4a18f3789",
            "6f4476ea5ad4434ab8c533e273d7db85",
            "807e418362154278be8dd803ee7ed183",
            "a2d62e0f35724e53ac295a611089f890",
            "69ad0b6987a74eab8548691d1ecc5d1a",
            "417ea99c20844dc39e845627f0c3f2de",
            "1b55dfcd6bb94753b6c14a34242667f0",
            "95806565414f45da971f244dc06d9383",
            "6257b1cadc0d44c28f92570828ddf399",
            "4ec55f44651543d1a7ea1f4f9c0679a0",
            "12f9b1dba6d94f42ac137ab515c8c4b5",
            "eb0b44457f404c74a6f8b3d7b6c9123f",
            "39fd115b98da4f639d9431f50a5562cf",
            "9f07ad75cee948aeaa89428148fa0759",
            "168c1ce83bf646e2849d6bcc26e4f061",
            "f1b04db7d5d941a5a7c9b01b66dd0749",
            "86e98b80862744e795ce6287dfa56602",
            "78a7bd953f5d45cf87035d3b6429e16b",
            "d16361e0dec440e8963927761dfa053b",
            "e07f13b148754680bd8132630734fb88",
            "4af1f0c4db7a49c7b0e1ac80c19c13a6",
            "d60d22a629f0463c88e525f99d3ed610",
            "5e3116aaca904f61a57528e253a48eb9",
            "285042db78444234938d0c65a9dcf310",
            "617ffa1a246645358954c51010390e0e",
            "71c1173f27f14b08ad09fcda7a279085",
            "f64d282188674bada3bf2867a19da1d9",
            "fe525c8919234251bb84b8f054ad1296",
            "0e3be36b2a634232878db11f8d3bd9b9",
            "31e22a264ad74e05bc192d4dd4719a6c",
            "10e3a37ee06440dda627e5b06c8fe598",
            "d3dc8b76e90e4785ab2fa9300928e548",
            "ffd990fd68ed4b9381f346fb93e14694",
            "ff576084e38441dabae17691c0efe928",
            "8f5834ac126445f8a34ae6ea00fea9c6",
            "bef8cc7055db40edb2549bc0550686e3",
            "861b24b3a62c4a4c99dc447d22c0d5cc",
            "a1c8fbff745d4b8db5058b0e4fac921b",
            "8dc4d5911f944f0eac505634468c0da7",
            "f982732f5f1c4069a78e5f72c195a646",
            "7c8d7937fe214a84a7983260914382aa",
            "10fdc77602e943d7b3da6c2b1ef918b6",
            "5e4f07930e6447dc85c33e10339d2f5c",
            "19820ce362da427da718a1a2729ba985",
            "7ae5ae92692447f6a91aea60459fcc84",
            "8e3e39d823a74653a3f41279f3865d04",
            "177fce9354a547c88bb5ebbe569e4181",
            "2bca80b1d239416f9179b55115c427fc",
            "20a66a17ebed4b0cb0bbec841a1bb6c8",
            "f7539a80be334febb302d61c2c24f61b",
            "7bd89e9dd3c848759366c87bc3cb2786",
            "42b9ed8d479e401fa502cc9c3911bb06",
            "656c7c858fd04e64b9e2bb2b07f65b5f",
            "c4791078c1f24931b7cca35e19da0d1f",
            "9c7d7cb8ad9c4ba69660a5e484b0b9be",
            "0d3573736db54af6b78204d8273b3063",
            "0ae13c2e92a54d9dbf96bd80b0dbe4b2",
            "024fbfb521b04e2fad5a7a34a81085eb",
            "d2ffef53e9e9475ca7066c7cda34a632",
            "042e4de552734e0e885eb2e6eb364e9c",
            "c4efd7fb8e644e82967e01d5ec4d18b5",
            "d071efc13f28433a95589f733782192b",
            "1b2c9d5e4b4948a4bd9d754e7f1cf1c7",
            "769882f9a3b543ffb4a199b565f4cdaf",
            "c1d6ecb8573d4a649e5f6ded47aede55",
            "6b1b66bdf47d4d99af036cc77263c6bc",
            "6f45bf47e54143cba2ba6c5e227472f6",
            "0959bb7330a941c0a5b7ed044413b425",
            "55278d257beb474ea080e47973c4f3ec",
            "c0b1ee6211a14d839fdcdd18ebe9aeab",
            "5faf2a2bb8e748ec88e67c4b804f2ba4",
            "55e80cf247cc48dd80c901e176da9ab6",
            "3c4ed9a418df49afbffadfaac270eb64",
            "cf4f8108508746279b81b77cc63fa386",
            "28bcc1be927e42f8bb2baef9652488b6"
          ]
        },
        "id": "x0Jdf48f7yGH",
        "outputId": "09f8ed21-50e5-4ef1-a489-25bf681d02c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing translation models...\n",
            "🔧 Setting up NLLB Translation Models:\n",
            "   Model: facebook/nllb-200-distilled-600M\n",
            "   Loading tokenizer and model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35542b5a2e494ecf840601f52695953f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f820473a11f444fa165d33b175917d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ec55f44651543d1a7ea1f4f9c0679a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4af1f0c4db7a49c7b0e1ac80c19c13a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3dc8b76e90e4785ab2fa9300928e548"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e4f07930e6447dc85c33e10339d2f5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4791078c1f24931b7cca35e19da0d1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d6ecb8573d4a649e5f6ded47aede55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✅ Model loaded successfully\n",
            "   Model parameters: 615,073,792\n",
            "\n",
            "🌍 Creating translation pipelines:\n",
            "   ✅ English → French\n",
            "   ✅ English → Spanish\n",
            "   ✅ English → German\n",
            "   ✅ English → Chinese (Simplified)\n",
            "   ✅ English → Japanese\n",
            "   ✅ English → Arabic\n",
            "   ✅ English → Hindi\n",
            "   ✅ English → Russian\n",
            "\n",
            "🎉 Created 8 translation pipelines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_translation_quality(translators, test_sentences=None):\n",
        "    \"\"\"\n",
        "    Test translation quality across multiple languages\n",
        "\n",
        "    Args:\n",
        "        translators: Dictionary of translation pipelines\n",
        "        test_sentences: List of test sentences\n",
        "\n",
        "    Returns:\n",
        "        Translation results\n",
        "    \"\"\"\n",
        "\n",
        "    if test_sentences is None:\n",
        "        test_sentences = [\n",
        "            \"Hello, how are you today?\",\n",
        "            \"The weather is beautiful outside.\",\n",
        "            \"I would like to order some food.\",\n",
        "            \"Where is the nearest hospital?\",\n",
        "            \"Thank you for your help.\",\n",
        "            \"Machine learning is transforming technology.\"\n",
        "        ]\n",
        "\n",
        "    print(\"🧪 Translation Quality Testing:\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        print(f\"\\n📝 Original: '{sentence}'\")\n",
        "        sentence_results = {}\n",
        "\n",
        "        for pair_id, translator_info in translation_models.items():\n",
        "            try:\n",
        "                translator = translator_info['pipeline']\n",
        "                config = translator_info['config']\n",
        "\n",
        "                # Perform translation\n",
        "                translation_result = translator(sentence)\n",
        "                translated_text = translation_result[0]['translation_text']\n",
        "\n",
        "                print(f\"   {config['name']:20}: '{translated_text}'\")\n",
        "\n",
        "                sentence_results[pair_id] = {\n",
        "                    'translation': translated_text,\n",
        "                    'target_language': config['tgt'],\n",
        "                    'language_name': config['name']\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   {config['name']:20}: ❌ Error - {e}\")\n",
        "                sentence_results[pair_id] = {'error': str(e)}\n",
        "\n",
        "        results[sentence] = sentence_results\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test translation quality if models are available\n",
        "if translation_models:\n",
        "    # [STUDENT ACTIVITY]: Students can add their own test sentences\n",
        "    custom_test_sentences = [\n",
        "        \"Hello, how are you today?\",\n",
        "        \"The weather is beautiful outside.\",\n",
        "        # Students add more sentences here\n",
        "    ]\n",
        "\n",
        "    translation_results = test_translation_quality(translation_models, custom_test_sentences)\n",
        "else:\n",
        "    print(\"⚠️ Translation models not available - skipping quality test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "C78FdE1e7yCH",
        "outputId": "24678d75-f9cf-4d7b-9652-edf55cc42428"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Translation Quality Testing:\n",
            "===================================\n",
            "\n",
            "📝 Original: 'Hello, how are you today?'\n",
            "   English → French    : 'Bonjour, comment allez-vous aujourd'hui ?'\n",
            "   English → Spanish   : 'Hola, ¿cómo estás hoy?'\n",
            "   English → German    : 'Hallo, wie geht's heute?'\n",
            "   English → Chinese (Simplified): '您好,今天您怎么样?'\n",
            "   English → Japanese  : 'こんにちは 今日はどうですか?'\n",
            "   English → Arabic    : 'مرحباً، كيف حالك اليوم؟'\n",
            "   English → Hindi     : 'हैलो, तुम आज कैसे हो?'\n",
            "   English → Russian   : 'Здравствуйте, как вы сегодня?'\n",
            "\n",
            "📝 Original: 'The weather is beautiful outside.'\n",
            "   English → French    : 'Le temps est beau dehors.'\n",
            "   English → Spanish   : 'El tiempo es hermoso afuera.'\n",
            "   English → German    : 'Das Wetter draußen ist schön.'\n",
            "   English → Chinese (Simplified): '外面天气很漂亮.'\n",
            "   English → Japanese  : '外は天気が美しい.'\n",
            "   English → Arabic    : 'الطقس جميل بالخارج'\n",
            "   English → Hindi     : 'बाहर मौसम खूबसूरत है।'\n",
            "   English → Russian   : 'На улице прекрасная погода.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio for Whisper\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to audio file\n",
        "        target_sr: Target sample rate (Whisper expects 16kHz)\n",
        "\n",
        "    Returns:\n",
        "        waveform: Preprocessed audio tensor\n",
        "        sample_rate: Sample rate\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Load audio file\n",
        "        waveform, original_sr = torchaudio.load(file_path)\n",
        "        print(f\"✅ Loaded audio: {file_path}\")\n",
        "        print(f\"   Original shape: {waveform.shape}\")\n",
        "        print(f\"   Original sample rate: {original_sr} Hz\")\n",
        "        print(f\"   Duration: {waveform.shape[1] / original_sr:.2f} seconds\")\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "            print(f\"   Converted to mono\")\n",
        "\n",
        "        # Resample if necessary\n",
        "        if original_sr != target_sr:\n",
        "            waveform = torchaudio.functional.resample(\n",
        "                waveform, orig_freq=original_sr, new_freq=target_sr\n",
        "            )\n",
        "            print(f\"   Resampled to {target_sr} Hz\")\n",
        "\n",
        "        # Normalize audio (Whisper expects normalized input)\n",
        "        waveform = waveform / torch.max(torch.abs(waveform))\n",
        "\n",
        "        print(f\"   Final shape: {waveform.shape}\")\n",
        "        print(f\"   Audio range: [{waveform.min():.3f}, {waveform.max():.3f}]\")\n",
        "\n",
        "        return waveform.squeeze().numpy(), target_sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading audio: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "OMdDdhWqACa9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part1"
      ],
      "metadata": {
        "id": "gfmSDtbyMFav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio from video files\n",
        "\n",
        "# !pip install moviepy\n",
        "\n",
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "\n",
        "def extract_audio(video_path, output_audio_path=None):\n",
        "    \"\"\"\n",
        "    从视频中提取音频并保存为 .wav 文件\n",
        "\n",
        "    参数：\n",
        "        video_path: 输入视频文件路径\n",
        "        output_audio_path: 输出音频文件路径，默认与视频同名\n",
        "\n",
        "    返回：\n",
        "        音频文件保存路径\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_path):\n",
        "        raise FileNotFoundError(f\"找不到视频文件：{video_path}\")\n",
        "\n",
        "    if output_audio_path is None:\n",
        "        output_audio_path = os.path.splitext(video_path)[0] + \".wav\"\n",
        "\n",
        "    video = VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(output_audio_path)\n",
        "    print(f\"音频提取完成，保存为：{output_audio_path}\")\n",
        "    return output_audio_path\n",
        "\n",
        "audio_path = extract_audio(\"video01.mp4\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiTl18CgME7Y",
        "outputId": "b6b88f90-cac3-4740-88a0-3075958b2790"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in video01.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "音频提取完成，保存为：video01.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio for Whisper\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to audio file\n",
        "        target_sr: Target sample rate (Whisper expects 16kHz)\n",
        "\n",
        "    Returns:\n",
        "        waveform: Preprocessed audio tensor\n",
        "        sample_rate: Sample rate\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Load audio file\n",
        "        waveform, original_sr = torchaudio.load(file_path)\n",
        "        print(f\"✅ Loaded audio: {file_path}\")\n",
        "        print(f\"   Original shape: {waveform.shape}\")\n",
        "        print(f\"   Original sample rate: {original_sr} Hz\")\n",
        "        print(f\"   Duration: {waveform.shape[1] / original_sr:.2f} seconds\")\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "            print(f\"   Converted to mono\")\n",
        "\n",
        "        # Resample if necessary\n",
        "        if original_sr != target_sr:\n",
        "            waveform = torchaudio.functional.resample(\n",
        "                waveform, orig_freq=original_sr, new_freq=target_sr\n",
        "            )\n",
        "            print(f\"   Resampled to {target_sr} Hz\")\n",
        "\n",
        "        # Normalize audio (Whisper expects normalized input)\n",
        "        waveform = waveform / torch.max(torch.abs(waveform))\n",
        "\n",
        "        print(f\"   Final shape: {waveform.shape}\")\n",
        "        print(f\"   Audio range: [{waveform.min():.3f}, {waveform.max():.3f}]\")\n",
        "\n",
        "        return waveform.squeeze().numpy(), target_sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading audio: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "ikUNjnCJME0y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Try to load sample audio\n",
        "try:\n",
        "\n",
        "    audio_data, sample_rate = load_and_preprocess_audio(audio_path)\n",
        "    audio_source = \"Downloaded sample\"\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Download failed: {e}\")\n",
        "    print(\"Creating synthetic speech-like signal for demonstration...\")\n",
        "\n",
        "    # Create a synthetic audio signal that resembles speech patterns\n",
        "    sample_rate = 16000\n",
        "    duration = 3.0\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Create a signal with speech-like characteristics\n",
        "    # Combine multiple frequencies to simulate formants\n",
        "    signal = (0.3 * np.sin(2 * np.pi * 200 * t) +  # F1 (low frequency)\n",
        "              0.2 * np.sin(2 * np.pi * 1000 * t) +  # F2 (mid frequency)\n",
        "              0.1 * np.sin(2 * np.pi * 2500 * t))   # F3 (high frequency)\n",
        "\n",
        "    # Add some amplitude modulation to simulate speech rhythm\n",
        "    envelope = 0.5 * (1 + np.sin(2 * np.pi * 3 * t))\n",
        "    audio_data = signal * envelope\n",
        "\n",
        "    # Normalize\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe1kso1HMEsk",
        "outputId": "3899106d-a29a-4441-af33-42017d67ea7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded audio: video01.wav\n",
            "   Original shape: torch.Size([2, 5707863])\n",
            "   Original sample rate: 44100 Hz\n",
            "   Duration: 129.43 seconds\n",
            "   Converted to mono\n",
            "   Resampled to 16000 Hz\n",
            "   Final shape: torch.Size([1, 2070880])\n",
            "   Audio range: [-0.660, 1.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    Do Whisper transcription WITH timestamps so we can merge later.\n",
        "    \"\"\"\n",
        "    print(f\"🎙️ Starting {task} with Whisper...\")\n",
        "    print(f\"   Language: {language if language else 'auto-detect'}\")\n",
        "    print(f\"   Audio duration: {len(audio_data)/16000:.2f} seconds\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_data,\n",
        "        language=language,\n",
        "        task=task,\n",
        "        verbose=False,\n",
        "        word_timestamps=True,      # <— 关键：拿词级时间戳\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_into_sentences(result, max_gap=0.8):\n",
        "    \"\"\"\n",
        "    把 Whisper 输出合并成“每段=完整一句话”。\n",
        "    优先用词级时间戳重建；没有则按段合并。\n",
        "    max_gap: 同一句里允许的最大相邻词静音间隔（秒）\n",
        "    \"\"\"\n",
        "    sentence_end = re.compile(r'[.!?…]+$')\n",
        "    merged = []\n",
        "\n",
        "    # --- 跑词级方案 ---\n",
        "    has_words = any('words' in s and s['words'] for s in result.get('segments', []))\n",
        "    if has_words:\n",
        "        cur_words = []\n",
        "        for seg in result['segments']:\n",
        "            for w in seg.get('words', []):\n",
        "                # w = {'word': 'Hello', 'start': 0.1, 'end': 0.5}\n",
        "                if not cur_words:\n",
        "                    cur_words.append(w)\n",
        "                    continue\n",
        "\n",
        "                gap = w['start'] - cur_words[-1]['end']\n",
        "                # 条件1：遇到句末标点；条件2：静音间隔太长——都认为要“收句”\n",
        "                if sentence_end.search(cur_words[-1]['word'].strip()) or gap > max_gap:\n",
        "                    text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "                    merged.append({\n",
        "                        'start': cur_words[0]['start'],\n",
        "                        'end':   cur_words[-1]['end'],\n",
        "                        'text':  re.sub(r'\\s+', ' ', text)\n",
        "                    })\n",
        "                    cur_words = [w]\n",
        "                else:\n",
        "                    cur_words.append(w)\n",
        "\n",
        "        if cur_words:\n",
        "            text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "            merged.append({\n",
        "                'start': cur_words[0]['start'],\n",
        "                'end':   cur_words[-1]['end'],\n",
        "                'text':  re.sub(r'\\s+', ' ', text)\n",
        "            })\n",
        "        return merged\n",
        "\n",
        "    # --- 退化：按段合并 ---\n",
        "    cur = None\n",
        "    for seg in result.get('segments', []):\n",
        "        if cur is None:\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "            continue\n",
        "\n",
        "        gap = seg['start'] - cur['end']\n",
        "        if sentence_end.search(cur['text']) or gap > max_gap:\n",
        "            merged.append(cur)\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "        else:\n",
        "            cur['end'] = seg['end']\n",
        "            cur['text'] = (cur['text'] + ' ' + seg['text']).strip()\n",
        "\n",
        "    if cur:\n",
        "        merged.append(cur)\n",
        "    return merged\n",
        "\n",
        "\n",
        "# ---------- 用法 ----------\n",
        "print(\"=\" * 50)\n",
        "print(\"BASIC SPEECH RECOGNITION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "result = transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\")\n",
        "\n",
        "print(\"\\n📝 Transcription Results:\")\n",
        "print(f\"Detected language: {result.get('language', 'unknown')}\")\n",
        "print(f\"Transcript (raw): '{result.get('text','').strip()}'\")\n",
        "\n",
        "sentences = merge_into_sentences(result, max_gap=0.8)\n",
        "\n",
        "def hhmmss(t):\n",
        "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "print(\"\\n=== Formatted (one sentence per segment) ===\")\n",
        "for s in sentences:\n",
        "    print(f\"[{hhmmss(s['start'])}] Speaker_A: {s['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0BYttQXM8Xw",
        "outputId": "aa556823-6977-4b3d-941c-4cb4c4d51650"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "BASIC SPEECH RECOGNITION\n",
            "==================================================\n",
            "🎙️ Starting transcribe with Whisper...\n",
            "   Language: auto-detect\n",
            "   Audio duration: 129.43 seconds\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12943/12943 [00:52<00:00, 245.07frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Transcription Results:\n",
            "Detected language: en\n",
            "Transcript (raw): 'No, I'm just kidding. That would be terrible. Hi, everyone. As I set up here, rather quietly, my name is Walker Stec. And I would like to talk to you guys about the connection between first impression and future relationship. Now, as I just stood up here, rather, er, oh my gosh, sorry. As I stood up here holding onto my index cards for dear life, you all did a little something called making a first impression. And it's not your fault. We all, oh my, I didn't get the clicker. Sorry, guys. Thank you. OK, so as humans, we form 10 to 20 images of what we think a person's personality is like, based on 15 seconds of conversation. Now, let's do the math. Not bad. Of these 10 to 20 images, let's say we meet two new people a day for seven days a week, that's about 200 new images that we have created of people just based on 200 seconds of conversation. Now, another fun fact. 85% of these images are going to be just dead wrong, not even in the same ballpark of what the person's personality is like. And only 15% are going to be remotely true of how they act around people. Now, let me tell you about a little personal narrative I wrote, ironically titled Making a First Impression by Maggie Scarf. In the article, Scarf talks about meeting a guy at a bar. The two get to talking. Things are going great. Little laughter, give, take conversation. Everything you look for in a good first impression. But she slips up. One bad reaction to a joke. She didn't laugh. And in one or two seconds of awkward silence, the two have shut down any chance of any sort of connection in the future. Now, I know what you're all thinking. Why do I need to hear a story about the girl who doesn't get the guy? And you don't. I'm not here to tell you about everyone's sad story, because I can't. There's too many. I am standing here in front of you today on this TEDx stage to make you aware of how seriously we all take these infamous first impressions. Now, after all these numbers and stories, some of you still might not be 100% sure about what it is I'm trying to say. So let me tell you. I am just asking you to consider my points. The next time you meet someone, ask a few more questions. Stay interested in their answers. Just keep the conversation.'\n",
            "\n",
            "=== Formatted (one sentence per segment) ===\n",
            "[00:00:00] Speaker_A: No, I'm just kidding.\n",
            "[00:00:01] Speaker_A: That would be terrible.\n",
            "[00:00:03] Speaker_A: Hi, everyone.\n",
            "[00:00:04] Speaker_A: As I set up here, rather quietly, my name is Walker Stec.\n",
            "[00:00:07] Speaker_A: And I would like to talk to you guys about the connection between first impression and future relationship.\n",
            "[00:00:11] Speaker_A: Now, as I just stood up here, rather, er, oh my gosh, sorry.\n",
            "[00:00:15] Speaker_A: As I stood up here holding onto my index cards for dear life, you all did a little something called making a first impression.\n",
            "[00:00:21] Speaker_A: And it's not your fault.\n",
            "[00:00:22] Speaker_A: We all, oh my, I didn't get the clicker.\n",
            "[00:00:27] Speaker_A: Sorry, guys.\n",
            "[00:00:30] Speaker_A: Thank you.\n",
            "[00:00:31] Speaker_A: OK, so as humans, we form 10 to 20 images of what we think a person's personality is like, based on 15 seconds of conversation.\n",
            "[00:00:40] Speaker_A: Now, let's do the math.\n",
            "[00:00:42] Speaker_A: Not bad.\n",
            "[00:00:42] Speaker_A: Of these 10 to 20 images, let's say we meet two new people a day for seven days a week, that's about 200 new images that we have created of people just based on 200 seconds of conversation.\n",
            "[00:00:54] Speaker_A: Now, another fun fact.\n",
            "[00:00:57] Speaker_A: 85 % of these images are going to be just dead wrong, not even in the same ballpark of what the person's personality is like.\n",
            "[00:01:03] Speaker_A: And only 15 % are going to be remotely true of how they act around people.\n",
            "[00:01:08] Speaker_A: Now, let me tell you about a little personal narrative I wrote, ironically titled Making a First Impression by Maggie Scarf.\n",
            "[00:01:14] Speaker_A: In the article, Scarf talks about meeting a guy at a bar.\n",
            "[00:01:17] Speaker_A: The two get to talking.\n",
            "[00:01:18] Speaker_A: Things are going great.\n",
            "[00:01:19] Speaker_A: Little laughter, give, take conversation.\n",
            "[00:01:22] Speaker_A: Everything you look for in a good first impression.\n",
            "[00:01:24] Speaker_A: But she slips up.\n",
            "[00:01:25] Speaker_A: One bad reaction to a joke.\n",
            "[00:01:27] Speaker_A: She didn't laugh.\n",
            "[00:01:28] Speaker_A: And in one or two seconds of awkward silence, the two have shut down any chance of any sort of connection in the future.\n",
            "[00:01:35] Speaker_A: Now, I know what you're all thinking.\n",
            "[00:01:36] Speaker_A: Why do I need to hear a story about the girl who doesn't get the guy?\n",
            "[00:01:40] Speaker_A: And you don't.\n",
            "[00:01:41] Speaker_A: I'm not here to tell you about everyone's sad story, because I can't.\n",
            "[00:01:44] Speaker_A: There's too many.\n",
            "[00:01:45] Speaker_A: I am standing here in front of you today on this TEDx stage to make you aware of how seriously we all take these infamous first impressions.\n",
            "[00:01:53] Speaker_A: Now, after all these numbers and stories, some of you still might not be 100 % sure about what it is I'm trying to say.\n",
            "[00:02:00] Speaker_A: So let me tell you.\n",
            "[00:02:01] Speaker_A: I am just asking you to consider my points.\n",
            "[00:02:03] Speaker_A: The next time you meet someone, ask a few more questions.\n",
            "[00:02:06] Speaker_A: Stay interested in their answers.\n",
            "[00:02:08] Speaker_A: Just keep the conversation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part2"
      ],
      "metadata": {
        "id": "beS0LrqFNBdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "from pylab import *\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "BbEmhUDVM8Vx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get video folders in list\n",
        "# expects each video in separate folder, with folder having the same name as the video\n",
        "test_folders_list = [\"video02.mp4\"]   # ← 这里填你的单个视频文件名或绝对路径\n",
        "\n",
        "(test_folders_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zGuhTn-zM8Tb",
        "outputId": "4c92d282-9fb2-46e8-fe54-a5f88d3944e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'video02.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os, cv2, json\n",
        "\n",
        "# ① 收集全部 video02.mp4 文件\n",
        "video_list   = [\"video02.mp4\"]   # 或 \"videos/*.mp4\"\n",
        "parent_dir   = \"extracted_faces\"\n",
        "os.makedirs(parent_dir, exist_ok=True)\n",
        "\n",
        "# ② 载入 OpenCV DNN 模型\n",
        "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\",\"res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "\n",
        "for vid_path in video_list:\n",
        "    video_name = os.path.splitext(os.path.basename(vid_path))[0]   # 'video01'\n",
        "    out_dir    = os.path.join(parent_dir, video_name)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    cap        = cv2.VideoCapture(vid_path)\n",
        "    fps        = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval   = int(fps * 2)                               # 每 2.5 秒抽 1 帧\n",
        "    frame_id   = saved = 0\n",
        "    meta       = []\n",
        "\n",
        "    while cap.isOpened() and saved < 100:                           # 每视频最多 10 张\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        if frame_id % interval == 0:\n",
        "            (h, w) = frame.shape[:2]\n",
        "            blob   = cv2.dnn.blobFromImage(cv2.resize(frame,(300,300)),1.0,\n",
        "                                           (300,300),(104.0,177.0,123.0))\n",
        "            net.setInput(blob)\n",
        "            dets   = net.forward()\n",
        "            for idx in range(dets.shape[2]):\n",
        "                if dets[0,0,idx,2] < 0.5: continue\n",
        "                x1,y1,x2,y2 = (dets[0,0,idx,3:7]*[w,h,w,h]).astype(int)\n",
        "                x1,y1 = max(x1-15,0), max(y1-15,0)\n",
        "                x2,y2 = min(x2+15,w-1), min(y2+15,h-1)\n",
        "                crop  = frame[y1:y2, x1:x2]\n",
        "                if crop.size == 0: continue\n",
        "                fname = f\"{video_name}_{saved}.jpg\"\n",
        "                cv2.imwrite(os.path.join(out_dir,fname), cv2.resize(crop,(299,299)))\n",
        "                meta.append({\"file\": fname, \"time\": frame_id/fps})\n",
        "                saved += 1\n",
        "                if saved >= 100: break\n",
        "        frame_id += 1\n",
        "    cap.release()\n",
        "    json.dump(meta, open(os.path.join(out_dir,\"faces_meta.json\"),\"w\"), indent=2)\n",
        "    print(f\"✅ {video_name}: saved {saved} faces → {out_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLN6wXReM8RU",
        "outputId": "9c16fcfd-4d95-4139-e721-eca2ce266b1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ video02: saved 100 faces → extracted_faces/video02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for face recognition, execute in terminal:\n",
        "# pip install facenet-pytorch\n",
        "# pip install 'opencv-python==4.9.0.80'\n",
        "# pip install 'pandas==2.2.1'"
      ],
      "metadata": {
        "id": "2xit86GpPGdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import face recognition libraries\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Face recognition libraries loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR7-zIU7M8Ov",
        "outputId": "50c8768c-0573-4976-95b9-a31a246680cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face recognition libraries loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MTCNN face detector\n",
        "mtcnn = MTCNN(\n",
        "    image_size=160,        # Output size for detected faces\n",
        "    margin=0,              # Margin around detected face\n",
        "    min_face_size=20,      # Minimum face size to detect\n",
        "    thresholds=[0.6, 0.7, 0.7],  # Detection thresholds for 3 stages\n",
        "    factor=0.709,          # Scaling factor between levels\n",
        "    post_process=True,     # Apply post-processing\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"MTCNN face detector initialized\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apZte_BYM8MZ",
        "outputId": "0fede13c-4b93-413a-a0ee-1a92058b9968"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MTCNN face detector initialized\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize face recognition model\n",
        "face_recognizer = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "print(\"InceptionResnetV1 face recognizer loaded\")\n",
        "print(f\"Model trained on: VGGFace2 dataset\")\n",
        "print(f\"Output dimension: 512 (face embedding vector)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "ab7b89200f6946c7992f9a4ca7529abe",
            "e8926727c305474db8a58b5fd23e84c1",
            "85b647b3ce284366a062113f447a7d0f",
            "df2248a4a74a4f688411842cbde490f4",
            "b7a2d7c37a5247daa6a11a32429a2a48",
            "fb83646e9387475299adf463ef139059",
            "d6cbb9071a2d4ff995a1564771f46ec1",
            "336e0b4b901c4ee0ab4799b6da0dc6b0",
            "6442c509f81b4f34ad262ceb900d106a",
            "38830a9b63034f5399380bd31ef1cc54",
            "b77c79d38e1b466e88f47d3a4ed953cf"
          ]
        },
        "id": "gz_u8lRIM8KD",
        "outputId": "8b367a90-724b-41ef-e464-dd89027a4c99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7b89200f6946c7992f9a4ca7529abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InceptionResnetV1 face recognizer loaded\n",
            "Model trained on: VGGFace2 dataset\n",
            "Output dimension: 512 (face embedding vector)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3UlMzJaM8Dt",
        "outputId": "fe05225f-a44a-4919-d166-1e3f39e2ed44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the test images dataset\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# Download test_images.zip if not available\n",
        "def download_test_images():\n",
        "    \"\"\"Download and extract test images for face recognition demo\"\"\"\n",
        "    try:\n",
        "        # Try to unzip if already downloaded\n",
        "        with zipfile.ZipFile('test_images.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "        print(\"test_images.zip extracted successfully!\")\n",
        "        return True\n",
        "    except FileNotFoundError:\n",
        "        print(\"test_images.zip not found. Please upload the test_images.zip file to continue.\")\n",
        "        print(\"This file should contain celebrity face images organized in folders by person name.\")\n",
        "        return False\n",
        "\n",
        "# Extract test images\n",
        "success = download_test_images()\n",
        "\n",
        "if success:\n",
        "    # Create custom collate function for DataLoader\n",
        "    def collate_fn(x):\n",
        "        return x[0]\n",
        "\n",
        "    # Load the face database using ImageFolder\n",
        "    face_dataset = datasets.ImageFolder('test_images')\n",
        "\n",
        "    # Create mapping from index to class name\n",
        "    face_dataset.idx_to_class = {i: c for c, i in face_dataset.class_to_idx.items()}\n",
        "\n",
        "    # Create data loader\n",
        "    face_loader = DataLoader(face_dataset, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    print(f\"Face database loaded successfully!\")\n",
        "    print(f\"Number of people in database: {len(face_dataset.classes)}\")\n",
        "    print(f\"Total images: {len(face_dataset)}\")\n",
        "    print(f\"People in database: {face_dataset.classes}\")\n",
        "\n",
        "    # Display database structure\n",
        "    for person_name in face_dataset.classes:\n",
        "        person_folder = os.path.join('test_images', person_name)\n",
        "        if os.path.exists(person_folder):\n",
        "            num_images = len([f for f in os.listdir(person_folder)\n",
        "                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            print(f\"  {person_name}: {num_images} images\")\n",
        "else:\n",
        "    print(\"Cannot proceed without test_images.zip. Please upload the file first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIOzyHBpM7_Q",
        "outputId": "16924182-56b9-45d0-b27b-75b02adaf1ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_images.zip extracted successfully!\n",
            "Face database loaded successfully!\n",
            "Number of people in database: 2\n",
            "Total images: 8\n",
            "People in database: ['A', 'B']\n",
            "  A: 4 images\n",
            "  B: 4 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process all images in the database to create face embeddings\n",
        "def build_face_database(face_loader, mtcnn, face_recognizer):\n",
        "    \"\"\"\n",
        "    Build face database by processing all images\n",
        "\n",
        "    Returns:\n",
        "        aligned_faces: Tensor of aligned face images\n",
        "        names: List of corresponding person names\n",
        "        embeddings: Face embeddings for database\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Building face database...\")\n",
        "    print(\"Processing images with MTCNN face detection...\")\n",
        "\n",
        "    aligned_faces = []\n",
        "    names = []\n",
        "\n",
        "    # Process each image in the dataset\n",
        "    for image, label in face_loader:\n",
        "        # Get person name from label\n",
        "        person_name = face_dataset.idx_to_class[label]\n",
        "\n",
        "        # Detect and align face\n",
        "        aligned_face, prob = mtcnn(image, return_prob=True)\n",
        "\n",
        "        if aligned_face is not None:\n",
        "            print(f'Face detected for {person_name} with probability: {prob:.4f}')\n",
        "            aligned_faces.append(aligned_face)\n",
        "            names.append(person_name)\n",
        "        else:\n",
        "            print(f'No face detected for {person_name}')\n",
        "\n",
        "    if len(aligned_faces) == 0:\n",
        "        print(\"No faces detected in any images!\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Convert to tensor for batch processing\n",
        "    aligned_tensor = torch.stack(aligned_faces).to(device)\n",
        "\n",
        "    print(f\"\\nGenerating face embeddings for {len(aligned_faces)} faces...\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    with torch.no_grad():\n",
        "        embeddings = face_recognizer(aligned_tensor).detach().cpu()\n",
        "\n",
        "    print(f\"Face database built successfully!\")\n",
        "    print(f\"Database contains {len(names)} face embeddings\")\n",
        "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
        "\n",
        "    return aligned_tensor, names, embeddings\n",
        "\n",
        "# Build the database if test images are available\n",
        "if success and 'face_dataset' in locals():\n",
        "    aligned_faces, database_names, database_embeddings = build_face_database(\n",
        "        face_loader, mtcnn, face_recognizer\n",
        "    )\n",
        "\n",
        "    if database_embeddings is not None:\n",
        "        print(f\"\\nDatabase Summary:\")\n",
        "        print(f\"People in database: {set(database_names)}\")\n",
        "        print(f\"Total face embeddings: {len(database_embeddings)}\")\n",
        "else:\n",
        "    print(\"Skipping database creation - test_images.zip not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL6UZQ_hM79D",
        "outputId": "44543a88-3011-46d9-f866-d9e934bb9f8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building face database...\n",
            "Processing images with MTCNN face detection...\n",
            "Face detected for A with probability: 1.0000\n",
            "Face detected for A with probability: 1.0000\n",
            "Face detected for A with probability: 1.0000\n",
            "Face detected for A with probability: 1.0000\n",
            "Face detected for B with probability: 0.9998\n",
            "Face detected for B with probability: 1.0000\n",
            "Face detected for B with probability: 1.0000\n",
            "Face detected for B with probability: 1.0000\n",
            "\n",
            "Generating face embeddings for 8 faces...\n",
            "Face database built successfully!\n",
            "Database contains 8 face embeddings\n",
            "Embedding dimension: 512\n",
            "\n",
            "Database Summary:\n",
            "People in database: {'B', 'A'}\n",
            "Total face embeddings: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_face_similarities(embeddings, names):\n",
        "    \"\"\"Analyze similarities between faces in the database\"\"\"\n",
        "\n",
        "    if embeddings is None or len(embeddings) == 0:\n",
        "        print(\"No embeddings available for analysis\")\n",
        "        return\n",
        "\n",
        "    # Calculate pairwise distances\n",
        "    distances = []\n",
        "    for i, emb1 in enumerate(embeddings):\n",
        "        row_distances = []\n",
        "        for j, emb2 in enumerate(embeddings):\n",
        "            distance = torch.norm(emb1 - emb2).item()\n",
        "            row_distances.append(distance)\n",
        "        distances.append(row_distances)\n",
        "\n",
        "    # Create distance matrix as DataFrame for better visualization\n",
        "    distance_df = pd.DataFrame(distances, columns=names, index=names)\n",
        "\n",
        "    print(\"Face Similarity Matrix (lower values = more similar):\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Visualize distance matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Create heatmap\n",
        "    import numpy as np\n",
        "    distance_matrix = np.array(distances)\n",
        "\n",
        "    plt.imshow(distance_matrix, cmap='viridis', interpolation='nearest')\n",
        "    plt.colorbar(label='Euclidean Distance')\n",
        "    plt.title('Face Similarity Matrix\\n(Darker = More Similar)')\n",
        "\n",
        "    # Add labels\n",
        "    plt.xticks(range(len(names)), names, rotation=45, ha='right')\n",
        "    plt.yticks(range(len(names)), names)\n",
        "\n",
        "    # Add distance values as text\n",
        "    for i in range(len(names)):\n",
        "        for j in range(len(names)):\n",
        "            plt.text(j, i, f'{distance_matrix[i, j]:.2f}',\n",
        "                    ha='center', va='center',\n",
        "                    color='white' if distance_matrix[i, j] > np.max(distance_matrix)/2 else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Find most and least similar pairs\n",
        "    min_distance = float('inf')\n",
        "    max_distance = 0\n",
        "    min_pair = None\n",
        "    max_pair = None\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        for j in range(i+1, len(names)):\n",
        "            dist = distance_matrix[i, j]\n",
        "            if dist < min_distance:\n",
        "                min_distance = dist\n",
        "                min_pair = (names[i], names[j])\n",
        "            if dist > max_distance:\n",
        "                max_distance = dist\n",
        "                max_pair = (names[i], names[j])\n",
        "\n",
        "    print(f\"\\nSimilarity Analysis:\")\n",
        "    print(f\"Most similar pair: {min_pair} (distance: {min_distance:.3f})\")\n",
        "    print(f\"Least similar pair: {max_pair} (distance: {max_distance:.3f})\")\n",
        "\n",
        "    return distance_df\n",
        "\n",
        "# Analyze face similarities if we have embeddings\n",
        "if 'database_embeddings' in locals() and database_embeddings is not None:\n",
        "    similarity_matrix = analyze_face_similarities(database_embeddings, database_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "zZEDRcmLM74O",
        "outputId": "01e76e9a-993e-4ed7-e591-31290efbe3b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face Similarity Matrix (lower values = more similar):\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similarity Analysis:\n",
            "Most similar pair: ('B', 'B') (distance: 0.378)\n",
            "Least similar pair: ('A', 'B') (distance: 1.471)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_query_face(query_image_path, mtcnn, face_recognizer, database_embeddings, database_names, threshold=1.0):\n",
        "    \"\"\"\n",
        "    Recognize a face from a query image\n",
        "\n",
        "    Args:\n",
        "        query_image_path: Path to query image\n",
        "        mtcnn: Face detection model\n",
        "        face_recognizer: Face recognition model\n",
        "        database_embeddings: Known face embeddings\n",
        "        database_names: Corresponding names\n",
        "        threshold: Recognition threshold\n",
        "\n",
        "    Returns:\n",
        "        result_dict: Recognition results\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        # Load query image\n",
        "        if isinstance(query_image_path, str):\n",
        "            query_image = cv2.imread(query_image_path)\n",
        "            if query_image is None:\n",
        "                raise ValueError(f\"Could not load image: {query_image_path}\")\n",
        "            # Convert BGR to RGB\n",
        "            query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
        "            query_image = Image.fromarray(query_image)\n",
        "        else:\n",
        "            query_image = query_image_path  # Assume it's already a PIL Image\n",
        "\n",
        "        print(f\"Processing query image: {query_image_path}\")\n",
        "\n",
        "        # Detect face\n",
        "        face_tensor, prob = mtcnn(query_image, return_prob=True)\n",
        "\n",
        "        if face_tensor is None:\n",
        "            return {\n",
        "                'status': 'No face detected',\n",
        "                'recognized_name': 'No Face',\n",
        "                'confidence': 0.0,\n",
        "                'distance': float('inf'),\n",
        "                'query_image': query_image\n",
        "            }\n",
        "\n",
        "        print(f\"Face detected with probability: {prob:.4f}\")\n",
        "\n",
        "        # Generate embedding\n",
        "        face_tensor = face_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            query_embedding = face_recognizer(face_tensor).detach().cpu()\n",
        "\n",
        "        # Compare with database\n",
        "        distances = []\n",
        "        for db_embedding in database_embeddings:\n",
        "            distance = torch.norm(query_embedding - db_embedding).item()\n",
        "            distances.append(distance)\n",
        "\n",
        "        # Find best match\n",
        "        min_distance = min(distances)\n",
        "        best_match_idx = distances.index(min_distance)\n",
        "\n",
        "        # Determine recognition result\n",
        "        if min_distance < threshold:\n",
        "            recognized_name = database_names[best_match_idx]\n",
        "            confidence = max(0, 1.0 - (min_distance / threshold))\n",
        "            status = 'Recognized'\n",
        "        else:\n",
        "            recognized_name = 'Unknown'\n",
        "            confidence = 0.0\n",
        "            status = 'Unknown person'\n",
        "\n",
        "        result = {\n",
        "            'status': status,\n",
        "            'recognized_name': recognized_name,\n",
        "            'confidence': confidence,\n",
        "            'distance': min_distance,\n",
        "            'all_distances': distances,\n",
        "            'query_image': query_image,\n",
        "            'detected_face': face_tensor.squeeze().cpu()\n",
        "        }\n",
        "\n",
        "        print(f\"Result: {recognized_name} (distance: {min_distance:.3f}, confidence: {confidence:.3f})\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing query: {str(e)}\")\n",
        "        return {\n",
        "            'status': f'Error: {str(e)}',\n",
        "            'recognized_name': 'Error',\n",
        "            'confidence': 0.0,\n",
        "            'distance': float('inf')\n",
        "        }"
      ],
      "metadata": {
        "id": "uNwYwO5iM71y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def classify_extracted_faces(extracted_folder='extracted_faces/video02', threshold=1.0):\n",
        "    \"\"\"\n",
        "    Recognize and group all extracted face images by identity\n",
        "\n",
        "    Returns:\n",
        "        grouped_faces: Dict of {recognized_name: [image_paths]}\n",
        "    \"\"\"\n",
        "    grouped_faces = defaultdict(list)\n",
        "\n",
        "    # 遍历文件夹\n",
        "    for filename in os.listdir(extracted_folder):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(extracted_folder, filename)\n",
        "\n",
        "            result = recognize_query_face(\n",
        "                image_path,\n",
        "                mtcnn,\n",
        "                face_recognizer,\n",
        "                database_embeddings,\n",
        "                database_names,\n",
        "                threshold=threshold\n",
        "            )\n",
        "\n",
        "            name = result['recognized_name']\n",
        "            grouped_faces[name].append(image_path)\n",
        "\n",
        "    return grouped_faces\n"
      ],
      "metadata": {
        "id": "WRbiuqI0M7v9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_faces = classify_extracted_faces(threshold=1.0)\n",
        "\n",
        "# 打印分组结果\n",
        "print(\"\\nGrouped Results:\")\n",
        "for person, images in grouped_faces.items():\n",
        "    print(f\"\\n🧑 {person} ({len(images)} images):\")\n",
        "    for img in images:\n",
        "        print(f\"  - {img}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc-bBmV0M7u7",
        "outputId": "7c9556ee-51b1-4f6a-fad2-4d779300b82b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing query image: extracted_faces/video02/video02_29.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.701, confidence: 0.299)\n",
            "Processing query image: extracted_faces/video02/video02_7.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.589, confidence: 0.411)\n",
            "Processing query image: extracted_faces/video02/video02_52.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.524, confidence: 0.476)\n",
            "Processing query image: extracted_faces/video02/video02_19.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.508, confidence: 0.492)\n",
            "Processing query image: extracted_faces/video02/video02_53.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.605, confidence: 0.395)\n",
            "Processing query image: extracted_faces/video02/video02_12.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: B (distance: 0.395, confidence: 0.605)\n",
            "Processing query image: extracted_faces/video02/video02_67.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.476, confidence: 0.524)\n",
            "Processing query image: extracted_faces/video02/video02_72.jpg\n",
            "Face detected with probability: 0.9996\n",
            "Result: B (distance: 0.627, confidence: 0.373)\n",
            "Processing query image: extracted_faces/video02/video02_49.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: A (distance: 0.801, confidence: 0.199)\n",
            "Processing query image: extracted_faces/video02/video02_47.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.758, confidence: 0.242)\n",
            "Processing query image: extracted_faces/video02/video02_5.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.543, confidence: 0.457)\n",
            "Processing query image: extracted_faces/video02/video02_18.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.377, confidence: 0.623)\n",
            "Processing query image: extracted_faces/video02/video02_44.jpg\n",
            "Face detected with probability: 0.9979\n",
            "Result: B (distance: 0.472, confidence: 0.528)\n",
            "Processing query image: extracted_faces/video02/video02_90.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.684, confidence: 0.316)\n",
            "Processing query image: extracted_faces/video02/video02_77.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.543, confidence: 0.457)\n",
            "Processing query image: extracted_faces/video02/video02_35.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.886, confidence: 0.114)\n",
            "Processing query image: extracted_faces/video02/video02_28.jpg\n",
            "Face detected with probability: 0.9993\n",
            "Result: B (distance: 0.390, confidence: 0.610)\n",
            "Processing query image: extracted_faces/video02/video02_14.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.483, confidence: 0.517)\n",
            "Processing query image: extracted_faces/video02/video02_48.jpg\n",
            "Face detected with probability: 0.9995\n",
            "Result: B (distance: 0.546, confidence: 0.454)\n",
            "Processing query image: extracted_faces/video02/video02_11.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: B (distance: 0.483, confidence: 0.517)\n",
            "Processing query image: extracted_faces/video02/video02_13.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.489, confidence: 0.511)\n",
            "Processing query image: extracted_faces/video02/video02_82.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.434, confidence: 0.566)\n",
            "Processing query image: extracted_faces/video02/video02_78.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.513, confidence: 0.487)\n",
            "Processing query image: extracted_faces/video02/video02_8.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.540, confidence: 0.460)\n",
            "Processing query image: extracted_faces/video02/video02_45.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: A (distance: 0.744, confidence: 0.256)\n",
            "Processing query image: extracted_faces/video02/video02_50.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.580, confidence: 0.420)\n",
            "Processing query image: extracted_faces/video02/video02_15.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.482, confidence: 0.518)\n",
            "Processing query image: extracted_faces/video02/video02_37.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: A (distance: 0.770, confidence: 0.230)\n",
            "Processing query image: extracted_faces/video02/video02_94.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.498, confidence: 0.502)\n",
            "Processing query image: extracted_faces/video02/video02_9.jpg\n",
            "Face detected with probability: 0.9977\n",
            "Result: B (distance: 0.595, confidence: 0.405)\n",
            "Processing query image: extracted_faces/video02/video02_42.jpg\n",
            "Face detected with probability: 0.9995\n",
            "Result: B (distance: 0.390, confidence: 0.610)\n",
            "Processing query image: extracted_faces/video02/video02_59.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.606, confidence: 0.394)\n",
            "Processing query image: extracted_faces/video02/video02_71.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.585, confidence: 0.415)\n",
            "Processing query image: extracted_faces/video02/video02_80.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.561, confidence: 0.439)\n",
            "Processing query image: extracted_faces/video02/video02_40.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.517, confidence: 0.483)\n",
            "Processing query image: extracted_faces/video02/video02_4.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.510, confidence: 0.490)\n",
            "Processing query image: extracted_faces/video02/video02_88.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.563, confidence: 0.437)\n",
            "Processing query image: extracted_faces/video02/video02_31.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.707, confidence: 0.293)\n",
            "Processing query image: extracted_faces/video02/video02_57.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.613, confidence: 0.387)\n",
            "Processing query image: extracted_faces/video02/video02_65.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.390, confidence: 0.610)\n",
            "Processing query image: extracted_faces/video02/video02_58.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.507, confidence: 0.493)\n",
            "Processing query image: extracted_faces/video02/video02_60.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.516, confidence: 0.484)\n",
            "Processing query image: extracted_faces/video02/video02_83.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.475, confidence: 0.525)\n",
            "Processing query image: extracted_faces/video02/video02_93.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.544, confidence: 0.456)\n",
            "Processing query image: extracted_faces/video02/video02_41.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.675, confidence: 0.325)\n",
            "Processing query image: extracted_faces/video02/video02_70.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: A (distance: 0.789, confidence: 0.211)\n",
            "Processing query image: extracted_faces/video02/video02_89.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.464, confidence: 0.536)\n",
            "Processing query image: extracted_faces/video02/video02_66.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.635, confidence: 0.365)\n",
            "Processing query image: extracted_faces/video02/video02_16.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.644, confidence: 0.356)\n",
            "Processing query image: extracted_faces/video02/video02_79.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.469, confidence: 0.531)\n",
            "Processing query image: extracted_faces/video02/video02_61.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.675, confidence: 0.325)\n",
            "Processing query image: extracted_faces/video02/video02_30.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.386, confidence: 0.614)\n",
            "Processing query image: extracted_faces/video02/video02_55.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.592, confidence: 0.408)\n",
            "Processing query image: extracted_faces/video02/video02_3.jpg\n",
            "Face detected with probability: 0.9996\n",
            "Result: B (distance: 0.448, confidence: 0.552)\n",
            "Processing query image: extracted_faces/video02/video02_63.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.769, confidence: 0.231)\n",
            "Processing query image: extracted_faces/video02/video02_23.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.647, confidence: 0.353)\n",
            "Processing query image: extracted_faces/video02/video02_74.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.459, confidence: 0.541)\n",
            "Processing query image: extracted_faces/video02/video02_36.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.674, confidence: 0.326)\n",
            "Processing query image: extracted_faces/video02/video02_73.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.556, confidence: 0.444)\n",
            "Processing query image: extracted_faces/video02/video02_26.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.426, confidence: 0.574)\n",
            "Processing query image: extracted_faces/video02/video02_87.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.454, confidence: 0.546)\n",
            "Processing query image: extracted_faces/video02/video02_99.jpg\n",
            "Face detected with probability: 0.9996\n",
            "Result: B (distance: 0.594, confidence: 0.406)\n",
            "Processing query image: extracted_faces/video02/video02_69.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.442, confidence: 0.558)\n",
            "Processing query image: extracted_faces/video02/video02_22.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.525, confidence: 0.475)\n",
            "Processing query image: extracted_faces/video02/video02_98.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.597, confidence: 0.403)\n",
            "Processing query image: extracted_faces/video02/video02_38.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.579, confidence: 0.421)\n",
            "Processing query image: extracted_faces/video02/video02_34.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.657, confidence: 0.343)\n",
            "Processing query image: extracted_faces/video02/video02_54.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.488, confidence: 0.512)\n",
            "Processing query image: extracted_faces/video02/video02_43.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.699, confidence: 0.301)\n",
            "Processing query image: extracted_faces/video02/video02_97.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: B (distance: 0.599, confidence: 0.401)\n",
            "Processing query image: extracted_faces/video02/video02_21.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.740, confidence: 0.260)\n",
            "Processing query image: extracted_faces/video02/video02_27.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.673, confidence: 0.327)\n",
            "Processing query image: extracted_faces/video02/video02_64.jpg\n",
            "Face detected with probability: 0.9998\n",
            "Result: A (distance: 0.548, confidence: 0.452)\n",
            "Processing query image: extracted_faces/video02/video02_1.jpg\n",
            "Face detected with probability: 0.9995\n",
            "Result: B (distance: 0.770, confidence: 0.230)\n",
            "Processing query image: extracted_faces/video02/video02_0.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.722, confidence: 0.278)\n",
            "Processing query image: extracted_faces/video02/video02_10.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.397, confidence: 0.603)\n",
            "Processing query image: extracted_faces/video02/video02_56.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.457, confidence: 0.543)\n",
            "Processing query image: extracted_faces/video02/video02_25.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.745, confidence: 0.255)\n",
            "Processing query image: extracted_faces/video02/video02_39.jpg\n",
            "Face detected with probability: 0.9985\n",
            "Result: B (distance: 0.541, confidence: 0.459)\n",
            "Processing query image: extracted_faces/video02/video02_33.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: A (distance: 0.681, confidence: 0.319)\n",
            "Processing query image: extracted_faces/video02/video02_75.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.542, confidence: 0.458)\n",
            "Processing query image: extracted_faces/video02/video02_92.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.663, confidence: 0.337)\n",
            "Processing query image: extracted_faces/video02/video02_86.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.512, confidence: 0.488)\n",
            "Processing query image: extracted_faces/video02/video02_91.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.606, confidence: 0.394)\n",
            "Processing query image: extracted_faces/video02/video02_24.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.494, confidence: 0.506)\n",
            "Processing query image: extracted_faces/video02/video02_76.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.560, confidence: 0.440)\n",
            "Processing query image: extracted_faces/video02/video02_32.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.652, confidence: 0.348)\n",
            "Processing query image: extracted_faces/video02/video02_95.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.459, confidence: 0.541)\n",
            "Processing query image: extracted_faces/video02/video02_84.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.502, confidence: 0.498)\n",
            "Processing query image: extracted_faces/video02/video02_46.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.601, confidence: 0.399)\n",
            "Processing query image: extracted_faces/video02/video02_96.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.800, confidence: 0.200)\n",
            "Processing query image: extracted_faces/video02/video02_20.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.570, confidence: 0.430)\n",
            "Processing query image: extracted_faces/video02/video02_2.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: A (distance: 0.661, confidence: 0.339)\n",
            "Processing query image: extracted_faces/video02/video02_68.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: A (distance: 0.585, confidence: 0.415)\n",
            "Processing query image: extracted_faces/video02/video02_85.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.466, confidence: 0.534)\n",
            "Processing query image: extracted_faces/video02/video02_17.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.451, confidence: 0.549)\n",
            "Processing query image: extracted_faces/video02/video02_81.jpg\n",
            "Face detected with probability: 0.9999\n",
            "Result: B (distance: 0.470, confidence: 0.530)\n",
            "Processing query image: extracted_faces/video02/video02_62.jpg\n",
            "Face detected with probability: 1.0000\n",
            "Result: B (distance: 0.633, confidence: 0.367)\n",
            "Processing query image: extracted_faces/video02/video02_6.jpg\n",
            "Face detected with probability: 0.9997\n",
            "Result: B (distance: 0.460, confidence: 0.540)\n",
            "Processing query image: extracted_faces/video02/video02_51.jpg\n",
            "Face detected with probability: 0.9995\n",
            "Result: B (distance: 0.583, confidence: 0.417)\n",
            "\n",
            "Grouped Results:\n",
            "\n",
            "🧑 A (50 images):\n",
            "  - extracted_faces/video02/video02_29.jpg\n",
            "  - extracted_faces/video02/video02_7.jpg\n",
            "  - extracted_faces/video02/video02_19.jpg\n",
            "  - extracted_faces/video02/video02_53.jpg\n",
            "  - extracted_faces/video02/video02_49.jpg\n",
            "  - extracted_faces/video02/video02_47.jpg\n",
            "  - extracted_faces/video02/video02_90.jpg\n",
            "  - extracted_faces/video02/video02_35.jpg\n",
            "  - extracted_faces/video02/video02_13.jpg\n",
            "  - extracted_faces/video02/video02_82.jpg\n",
            "  - extracted_faces/video02/video02_78.jpg\n",
            "  - extracted_faces/video02/video02_8.jpg\n",
            "  - extracted_faces/video02/video02_45.jpg\n",
            "  - extracted_faces/video02/video02_50.jpg\n",
            "  - extracted_faces/video02/video02_15.jpg\n",
            "  - extracted_faces/video02/video02_37.jpg\n",
            "  - extracted_faces/video02/video02_80.jpg\n",
            "  - extracted_faces/video02/video02_4.jpg\n",
            "  - extracted_faces/video02/video02_88.jpg\n",
            "  - extracted_faces/video02/video02_31.jpg\n",
            "  - extracted_faces/video02/video02_58.jpg\n",
            "  - extracted_faces/video02/video02_60.jpg\n",
            "  - extracted_faces/video02/video02_41.jpg\n",
            "  - extracted_faces/video02/video02_70.jpg\n",
            "  - extracted_faces/video02/video02_66.jpg\n",
            "  - extracted_faces/video02/video02_16.jpg\n",
            "  - extracted_faces/video02/video02_63.jpg\n",
            "  - extracted_faces/video02/video02_23.jpg\n",
            "  - extracted_faces/video02/video02_74.jpg\n",
            "  - extracted_faces/video02/video02_73.jpg\n",
            "  - extracted_faces/video02/video02_98.jpg\n",
            "  - extracted_faces/video02/video02_38.jpg\n",
            "  - extracted_faces/video02/video02_54.jpg\n",
            "  - extracted_faces/video02/video02_43.jpg\n",
            "  - extracted_faces/video02/video02_21.jpg\n",
            "  - extracted_faces/video02/video02_27.jpg\n",
            "  - extracted_faces/video02/video02_64.jpg\n",
            "  - extracted_faces/video02/video02_0.jpg\n",
            "  - extracted_faces/video02/video02_10.jpg\n",
            "  - extracted_faces/video02/video02_56.jpg\n",
            "  - extracted_faces/video02/video02_25.jpg\n",
            "  - extracted_faces/video02/video02_33.jpg\n",
            "  - extracted_faces/video02/video02_92.jpg\n",
            "  - extracted_faces/video02/video02_86.jpg\n",
            "  - extracted_faces/video02/video02_76.jpg\n",
            "  - extracted_faces/video02/video02_95.jpg\n",
            "  - extracted_faces/video02/video02_84.jpg\n",
            "  - extracted_faces/video02/video02_96.jpg\n",
            "  - extracted_faces/video02/video02_2.jpg\n",
            "  - extracted_faces/video02/video02_68.jpg\n",
            "\n",
            "🧑 B (50 images):\n",
            "  - extracted_faces/video02/video02_52.jpg\n",
            "  - extracted_faces/video02/video02_12.jpg\n",
            "  - extracted_faces/video02/video02_67.jpg\n",
            "  - extracted_faces/video02/video02_72.jpg\n",
            "  - extracted_faces/video02/video02_5.jpg\n",
            "  - extracted_faces/video02/video02_18.jpg\n",
            "  - extracted_faces/video02/video02_44.jpg\n",
            "  - extracted_faces/video02/video02_77.jpg\n",
            "  - extracted_faces/video02/video02_28.jpg\n",
            "  - extracted_faces/video02/video02_14.jpg\n",
            "  - extracted_faces/video02/video02_48.jpg\n",
            "  - extracted_faces/video02/video02_11.jpg\n",
            "  - extracted_faces/video02/video02_94.jpg\n",
            "  - extracted_faces/video02/video02_9.jpg\n",
            "  - extracted_faces/video02/video02_42.jpg\n",
            "  - extracted_faces/video02/video02_59.jpg\n",
            "  - extracted_faces/video02/video02_71.jpg\n",
            "  - extracted_faces/video02/video02_40.jpg\n",
            "  - extracted_faces/video02/video02_57.jpg\n",
            "  - extracted_faces/video02/video02_65.jpg\n",
            "  - extracted_faces/video02/video02_83.jpg\n",
            "  - extracted_faces/video02/video02_93.jpg\n",
            "  - extracted_faces/video02/video02_89.jpg\n",
            "  - extracted_faces/video02/video02_79.jpg\n",
            "  - extracted_faces/video02/video02_61.jpg\n",
            "  - extracted_faces/video02/video02_30.jpg\n",
            "  - extracted_faces/video02/video02_55.jpg\n",
            "  - extracted_faces/video02/video02_3.jpg\n",
            "  - extracted_faces/video02/video02_36.jpg\n",
            "  - extracted_faces/video02/video02_26.jpg\n",
            "  - extracted_faces/video02/video02_87.jpg\n",
            "  - extracted_faces/video02/video02_99.jpg\n",
            "  - extracted_faces/video02/video02_69.jpg\n",
            "  - extracted_faces/video02/video02_22.jpg\n",
            "  - extracted_faces/video02/video02_34.jpg\n",
            "  - extracted_faces/video02/video02_97.jpg\n",
            "  - extracted_faces/video02/video02_1.jpg\n",
            "  - extracted_faces/video02/video02_39.jpg\n",
            "  - extracted_faces/video02/video02_75.jpg\n",
            "  - extracted_faces/video02/video02_91.jpg\n",
            "  - extracted_faces/video02/video02_24.jpg\n",
            "  - extracted_faces/video02/video02_32.jpg\n",
            "  - extracted_faces/video02/video02_46.jpg\n",
            "  - extracted_faces/video02/video02_20.jpg\n",
            "  - extracted_faces/video02/video02_85.jpg\n",
            "  - extracted_faces/video02/video02_17.jpg\n",
            "  - extracted_faces/video02/video02_81.jpg\n",
            "  - extracted_faces/video02/video02_62.jpg\n",
            "  - extracted_faces/video02/video02_6.jpg\n",
            "  - extracted_faces/video02/video02_51.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def save_grouped_faces(grouped_faces, output_root=\"grouped_output\"):\n",
        "    \"\"\"Save grouped faces into subdirectories under output_root\"\"\"\n",
        "    os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "    for label, image_paths in grouped_faces.items():\n",
        "        label_folder = os.path.join(output_root, label)\n",
        "        os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "        for img_path in image_paths:\n",
        "            # 复制图像到目标子文件夹\n",
        "            filename = os.path.basename(img_path)\n",
        "            dest_path = os.path.join(label_folder, filename)\n",
        "            shutil.copy(img_path, dest_path)\n",
        "\n",
        "    print(f\"\\n✅ All grouped images saved to '{output_root}'\")\n",
        "\n",
        "# 保存分组图像\n",
        "save_grouped_faces(grouped_faces)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8p1h_DGM7qw",
        "outputId": "8b663f13-bafe-4139-97c7-b8cb83cea2f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ All grouped images saved to 'grouped_output'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the audio from video02.mp4\n",
        "\n",
        "audio_path_02 = extract_audio(\"video02.mp4\")\n",
        "\n",
        "# Try to load sample audio\n",
        "try:\n",
        "\n",
        "    audio_data, sample_rate = load_and_preprocess_audio(audio_path_02)\n",
        "    audio_source = \"Downloaded sample video02\"\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Download failed: {e}\")\n",
        "    print(\"Creating synthetic speech-like signal for demonstration...\")\n",
        "\n",
        "    # Create a synthetic audio signal that resembles speech patterns\n",
        "    sample_rate = 16000\n",
        "    duration = 3.0\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Create a signal with speech-like characteristics\n",
        "    # Combine multiple frequencies to simulate formants\n",
        "    signal = (0.3 * np.sin(2 * np.pi * 200 * t) +  # F1 (low frequency)\n",
        "              0.2 * np.sin(2 * np.pi * 1000 * t) +  # F2 (mid frequency)\n",
        "              0.1 * np.sin(2 * np.pi * 2500 * t))   # F3 (high frequency)\n",
        "\n",
        "    # Add some amplitude modulation to simulate speech rhythm\n",
        "    envelope = 0.5 * (1 + np.sin(2 * np.pi * 3 * t))\n",
        "    audio_data = signal * envelope\n",
        "\n",
        "    # Normalize\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KorlcHMMM7nW",
        "outputId": "f2adaf19-17f0-4481-fd4a-1248af83804b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in video02.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "音频提取完成，保存为：video02.wav\n",
            "✅ Loaded audio: video02.wav\n",
            "   Original shape: torch.Size([2, 6313797])\n",
            "   Original sample rate: 44100 Hz\n",
            "   Duration: 143.17 seconds\n",
            "   Converted to mono\n",
            "   Resampled to 16000 Hz\n",
            "   Final shape: torch.Size([1, 2290720])\n",
            "   Audio range: [-0.890, 1.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    Do Whisper transcription WITH timestamps so we can merge later.\n",
        "    \"\"\"\n",
        "    print(f\"🎙️ Starting {task} with Whisper...\")\n",
        "    print(f\"   Language: {language if language else 'auto-detect'}\")\n",
        "    print(f\"   Audio duration: {len(audio_data)/16000:.2f} seconds\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_data,\n",
        "        language=language,\n",
        "        task=task,\n",
        "        verbose=False,\n",
        "        word_timestamps=True,      # <— 关键：拿词级时间戳\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_into_sentences(result, max_gap=0.8):\n",
        "    \"\"\"\n",
        "    把 Whisper 输出合并成“每段=完整一句话”。\n",
        "    优先用词级时间戳重建；没有则按段合并。\n",
        "    max_gap: 同一句里允许的最大相邻词静音间隔（秒）\n",
        "    \"\"\"\n",
        "    sentence_end = re.compile(r'[.!?…]+$')\n",
        "    merged = []\n",
        "\n",
        "    # --- 跑词级方案 ---\n",
        "    has_words = any('words' in s and s['words'] for s in result.get('segments', []))\n",
        "    if has_words:\n",
        "        cur_words = []\n",
        "        for seg in result['segments']:\n",
        "            for w in seg.get('words', []):\n",
        "                # w = {'word': 'Hello', 'start': 0.1, 'end': 0.5}\n",
        "                if not cur_words:\n",
        "                    cur_words.append(w)\n",
        "                    continue\n",
        "\n",
        "                gap = w['start'] - cur_words[-1]['end']\n",
        "                # 条件1：遇到句末标点；条件2：静音间隔太长——都认为要“收句”\n",
        "                if sentence_end.search(cur_words[-1]['word'].strip()) or gap > max_gap:\n",
        "                    text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "                    merged.append({\n",
        "                        'start': cur_words[0]['start'],\n",
        "                        'end':   cur_words[-1]['end'],\n",
        "                        'text':  re.sub(r'\\s+', ' ', text)\n",
        "                    })\n",
        "                    cur_words = [w]\n",
        "                else:\n",
        "                    cur_words.append(w)\n",
        "\n",
        "        if cur_words:\n",
        "            text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "            merged.append({\n",
        "                'start': cur_words[0]['start'],\n",
        "                'end':   cur_words[-1]['end'],\n",
        "                'text':  re.sub(r'\\s+', ' ', text)\n",
        "            })\n",
        "        return merged\n",
        "\n",
        "    # --- 退化：按段合并 ---\n",
        "    cur = None\n",
        "    for seg in result.get('segments', []):\n",
        "        if cur is None:\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "            continue\n",
        "\n",
        "        gap = seg['start'] - cur['end']\n",
        "        if sentence_end.search(cur['text']) or gap > max_gap:\n",
        "            merged.append(cur)\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "        else:\n",
        "            cur['end'] = seg['end']\n",
        "            cur['text'] = (cur['text'] + ' ' + seg['text']).strip()\n",
        "\n",
        "    if cur:\n",
        "        merged.append(cur)\n",
        "    return merged\n",
        "\n",
        "\n",
        "# ---------- 用法 ----------\n",
        "print(\"=\" * 50)\n",
        "print(\"BASIC SPEECH RECOGNITION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "result = transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\")\n",
        "\n",
        "print(\"\\n📝 Transcription Results:\")\n",
        "print(f\"Detected language: {result.get('language', 'unknown')}\")\n",
        "print(f\"Transcript (raw): '{result.get('text','').strip()}'\")\n",
        "\n",
        "sentences = merge_into_sentences(result, max_gap=0.8)\n",
        "\n",
        "def hhmmss(t):\n",
        "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "print(\"\\n=== Formatted (one sentence per segment) ===\")\n",
        "for s in sentences:\n",
        "    print(f\"[{hhmmss(s['start'])}] Speaker_A: {s['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp2JSvXTRfP5",
        "outputId": "5041d3eb-0eba-4814-92eb-10d24649f5b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "BASIC SPEECH RECOGNITION\n",
            "==================================================\n",
            "🎙️ Starting transcribe with Whisper...\n",
            "   Language: auto-detect\n",
            "   Audio duration: 143.17 seconds\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14317/14317 [01:03<00:00, 225.93frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Transcription Results:\n",
            "Detected language: en\n",
            "Transcript (raw): 'video we're going to cover how to do an interview with the host and a guest on camera at the same time. Now you can see we both have a little microphone on this, a lavalier microphone. We're running them into a Y splitter and then from that we're going into that KD connector that goes into the iPad, the iPhone, or whatever you're recording into. So I have with me today my guest is Keith Gilmore. Keith, could you tell us a little bit about yourself? Yeah, but a copywriter for the last seven years and basically helped to make the create the best messages that are the most compelling for my clients. So a copywriting thing is not a legal thing, it's more of a sales marketing. No, it's not the marketing scene with a little circle around it. Yeah, it's along the lines of all things marketing. Great, well thank you. So one of the things we're checking right here is the volume of how he speaks and how I speak and making sure we have some rhythm and before we really get into the meat of what we're going to be talking about, we're just having some banter back and forth. So we're checking our audio levels and that as he's talking or I'm talking, I'm not talking, then I kind of drop off and stuff like that. You want to make sure that you're both speaking loud and clear and that if you do have a VU meter or that meter, you're not peeking into the red, you're staying with the top of that green and into the yellow of using say, Filmic Pro. That's what we really like to do is make sure you have a nice strong signal. So even though we're very close together here, we're about, what would you say, maybe 18 inches or two feet apart? No, it's really, I'm talking past him, he's talking past me. It's not like a just a quiet conversation we'd have if we were actually this close. The other thing is he and I are sitting relatively close, but on TV, it always looks like people are further apart. So I'm actually, I have my legs crossed and I, this is normally we would sit this close together. This is kind of uncomfortable, but on camera, it doesn't look so bad. So let's do one more test for the audio and we'll make sure that both the volume of what I'm speaking and here is speaking is relatively the same. So Keith, could you tell us a little bit about copywriting? What is what is one thing that people really need to think about when they are having to look at good copy or right good copy? Sure, always think about who you're writing to.'\n",
            "\n",
            "=== Formatted (one sentence per segment) ===\n",
            "[00:00:00] Speaker_A: video we're going to cover how to do an interview with the host and a guest on camera at the same time.\n",
            "[00:00:05] Speaker_A: Now you can see we both have a little microphone on this, a lavalier microphone.\n",
            "[00:00:09] Speaker_A: We're running them into a Y splitter and then from that we're going into that KD connector that goes into the iPad, the iPhone, or whatever you're recording into.\n",
            "[00:00:18] Speaker_A: So I have with me today my guest is Keith Gilmore.\n",
            "[00:00:22] Speaker_A: Keith, could you tell us a little bit about yourself?\n",
            "[00:00:24] Speaker_A: Yeah, but a copywriter for the last seven years and basically helped to make the create the best messages that are the most compelling for my clients.\n",
            "[00:00:37] Speaker_A: So a copywriting thing is not a legal thing, it's more of a sales marketing.\n",
            "[00:00:39] Speaker_A: No, it's not the marketing scene with a little circle around it.\n",
            "[00:00:44] Speaker_A: Yeah, it's along the lines of all things marketing.\n",
            "[00:00:48] Speaker_A: Great, well thank you.\n",
            "[00:00:50] Speaker_A: So one of the things we're checking right here is the volume of how he speaks and how I speak and making sure we have some rhythm and before we really get into the meat of what we're going to be talking about, we're just having some banter back and forth.\n",
            "[00:01:02] Speaker_A: So we're checking our audio levels and that as he's talking or I'm talking, I'm not talking, then I kind of drop off and stuff like that.\n",
            "[00:01:10] Speaker_A: You want to make sure that you're both speaking loud and clear and that if you do have a VU meter or that meter, you're not peeking into the red, you're staying with the top of that green and into the yellow of using say, Filmic Pro.\n",
            "[00:01:22] Speaker_A: That's what we really like to do is make sure you have a nice strong signal.\n",
            "[00:01:26] Speaker_A: So even though we're very close together here, we're about, what would you say, maybe 18 inches or two feet apart?\n",
            "[00:01:32] Speaker_A: No, it's really, I'm talking past him, he's talking past me.\n",
            "[00:01:37] Speaker_A: It's not like a just a quiet conversation we'd have if we were actually this close.\n",
            "[00:01:42] Speaker_A: The other thing is he and I are sitting relatively close, but on TV, it always looks like people are further apart.\n",
            "[00:01:49] Speaker_A: So I'm actually, I have my legs crossed and I,\n",
            "[00:01:52] Speaker_A: this is normally we would sit this close together.\n",
            "[00:01:55] Speaker_A: This is kind of uncomfortable, but on camera, it doesn't look so bad.\n",
            "[00:01:58] Speaker_A: So let's do one more test for the audio and we'll make sure that both the volume of what I'm speaking and here is speaking is relatively the same.\n",
            "[00:02:09] Speaker_A: So Keith, could you tell us a little bit about copywriting?\n",
            "[00:02:12] Speaker_A: What is what is one thing that people really need to think about when they are having to look at good copy or right good copy?\n",
            "[00:02:20] Speaker_A: Sure, always think about who you're writing to.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "OUTPUT_DIR = \"/content/sentences_out\"  # 你想要保存的路径\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)  # exist_ok=True 表示如果已存在不会报错\n",
        "\n",
        "print(f\"✅ 文件夹已准备好：{OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "jp1d-AiwRfNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38445e9-c035-4369-d7d2-432d298b319a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 文件夹已准备好：/content/sentences_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- (一次性) 依赖安装：在 Colab 可直接运行 ---\n",
        "# !pip -q install pydub openai-whisper\n",
        "\n",
        "import os, re, unicodedata, math\n",
        "from pathlib import Path\n",
        "from pydub import AudioSegment\n",
        "\n",
        "try:\n",
        "    import whisper  # 如果你已有 model 对象，可以忽略加载\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# ============== 配置区（根据你的情况修改） ==============\n",
        "# 1) 如果你从“文件”开始，填路径（常见）：\n",
        "INPUT_AUDIO = \"/content/video02.wav\"   # 支持 wav/mp3/m4a 等\n",
        "OUTPUT_DIR  = \"/content/sentences_out\"\n",
        "\n",
        "# 2) 如果你已经有 whisper 的 model 和 audio_data，可把下面两行设为 None，并使用你现成的对象\n",
        "MODEL_SIZE  = \"base\"   # tiny/base/small/medium/large (根据你的显存和速度选择)\n",
        "USE_FILE_INPUT = True  # True：走文件路径；False：使用你现成的 audio_data 变量\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "def load_whisper_model(name=\"base\"):\n",
        "    print(f\"🚀 Loading Whisper model: {name}\")\n",
        "    return whisper.load_model(name)\n",
        "\n",
        "\n",
        "def transcribe_with_whisper(model, audio_source, language=None, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    audio_source: 如果是 numpy 数组(16k 单声道)就直接传数组；如果是路径就传 str/path。\n",
        "    \"\"\"\n",
        "    print(f\"🎙️ Starting {task} with Whisper...\")\n",
        "    print(f\"   Language: {language if language else 'auto-detect'}\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_source,\n",
        "        language=language,\n",
        "        task=task,\n",
        "        verbose=False,\n",
        "        word_timestamps=True,      # 关键：拿词级时间戳\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_into_sentences(result, max_gap=0.8):\n",
        "    \"\"\"\n",
        "    把 Whisper 输出合并成“每段=完整一句话”。\n",
        "    优先用词级时间戳重建；没有则按段合并。\n",
        "    max_gap: 同一句里允许的最大相邻词静音间隔（秒）\n",
        "    \"\"\"\n",
        "    sentence_end = re.compile(r'[.!?…]+$')\n",
        "    merged = []\n",
        "\n",
        "    # --- 跑词级方案 ---\n",
        "    has_words = any('words' in s and s['words'] for s in result.get('segments', []))\n",
        "    if has_words:\n",
        "        cur_words = []\n",
        "        for seg in result['segments']:\n",
        "            for w in seg.get('words', []):\n",
        "                # w = {'word': 'Hello', 'start': 0.1, 'end': 0.5}\n",
        "                if not cur_words:\n",
        "                    cur_words.append(w)\n",
        "                    continue\n",
        "\n",
        "                gap = w['start'] - cur_words[-1]['end']\n",
        "                # 条件1：遇到句末标点；条件2：静音间隔太长——都认为要“收句”\n",
        "                if sentence_end.search(cur_words[-1]['word'].strip()) or gap > max_gap:\n",
        "                    text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "                    merged.append({\n",
        "                        'start': cur_words[0]['start'],\n",
        "                        'end':   cur_words[-1]['end'],\n",
        "                        'text':  re.sub(r'\\s+', ' ', text)\n",
        "                    })\n",
        "                    cur_words = [w]\n",
        "                else:\n",
        "                    cur_words.append(w)\n",
        "\n",
        "        if cur_words:\n",
        "            text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "            merged.append({\n",
        "                'start': cur_words[0]['start'],\n",
        "                'end':   cur_words[-1]['end'],\n",
        "                'text':  re.sub(r'\\s+', ' ', text)\n",
        "            })\n",
        "        return merged\n",
        "\n",
        "    # --- 退化：按段合并 ---\n",
        "    cur = None\n",
        "    for seg in result.get('segments', []):\n",
        "        if cur is None:\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "            continue\n",
        "\n",
        "        gap = seg['start'] - cur['end']\n",
        "        if sentence_end.search(cur['text']) or gap > max_gap:\n",
        "            merged.append(cur)\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "        else:\n",
        "            cur['end'] = seg['end']\n",
        "            cur['text'] = (cur['text'] + ' ' + seg['text']).strip()\n",
        "\n",
        "    if cur:\n",
        "        merged.append(cur)\n",
        "    return merged\n",
        "\n",
        "\n",
        "def hhmmss(t):\n",
        "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "\n",
        "def _safe_snippet(text, maxlen=40):\n",
        "    # 用于文件名：去掉奇怪符号/控制字符/过长文本\n",
        "    text = unicodedata.normalize(\"NFKC\", text).strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\u4e00-\\u9fff _-]\", \"\", text)  # 保留中英文字母、数字、空格、下划线、短横\n",
        "    if len(text) > maxlen:\n",
        "        text = text[:maxlen].rstrip()\n",
        "    return text or \"clip\"\n",
        "\n",
        "\n",
        "def save_sentence_clips(input_audio_path, sentences, out_dir, fmt=\"wav\"):\n",
        "    \"\"\"\n",
        "    用 pydub 按句裁切音频并保存。\n",
        "    注意：如果你最初传给 whisper 的是数组，这里仍需要原始音频文件路径来读取波形。\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    audio = AudioSegment.from_file(input_audio_path)  # 自动识别格式\n",
        "\n",
        "    saved_files = []\n",
        "    for i, s in enumerate(sentences, start=1):\n",
        "        start_ms = max(0, int(math.floor(s['start'] * 1000)))\n",
        "        end_ms   = max(start_ms + 1, int(math.ceil(s['end'] * 1000)))  # 至少 1ms，避免空切片\n",
        "        chunk = audio[start_ms:end_ms]\n",
        "\n",
        "        # 构造更友好的文件名：编号_起止_文本片段.wav\n",
        "        t1, t2 = hhmmss(s['start']).replace(\":\", \"-\"), hhmmss(s['end']).replace(\":\", \"-\")\n",
        "        snippet = _safe_snippet(s['text'])\n",
        "        fname = f\"{i:03d}_{t1}_{t2}_{snippet}.{fmt}\"\n",
        "        fpath = str(Path(out_dir) / fname)\n",
        "\n",
        "        chunk.export(fpath, format=fmt)\n",
        "        saved_files.append(fpath)\n",
        "    return saved_files\n",
        "\n",
        "\n",
        "# ====================== 主流程 ======================\n",
        "print(\"=\" * 50)\n",
        "print(\"BASIC SPEECH RECOGNITION + SENTENCE SPLITTING + CLIP SAVING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "\n",
        "if USE_FILE_INPUT:\n",
        "    # 从音频“文件”开始\n",
        "    audio_source = INPUT_AUDIO\n",
        "else:\n",
        "    # 已有 16k 单声道 numpy 数组：audio_data\n",
        "    # audio_source = audio_data  # ← 解注释并确保变量存在\n",
        "    raise ValueError(\"请把 USE_FILE_INPUT 设为 True 或提供 audio_data 变量。\")\n",
        "\n",
        "# 转写\n",
        "result = transcribe_with_whisper(model, audio_source, language=None, task=\"transcribe\")\n",
        "\n",
        "# print(\"\\n📝 Transcription Results:\")\n",
        "# print(f\"Detected language: {result.get('language', 'unknown')}\")\n",
        "# print(f\"Transcript (raw): '{result.get('text','').strip()}'\")\n",
        "\n",
        "# 合并为“每句一段”\n",
        "sentences = merge_into_sentences(result, max_gap=0.8)\n",
        "\n",
        "# print(\"\\n=== Formatted (one sentence per segment) ===\")\n",
        "# for s in sentences:\n",
        "#     print(f\"[{hhmmss(s['start'])}] Speaker_A: {s['text']}\")\n",
        "\n",
        "# 按句裁剪并保存\n",
        "saved = save_sentence_clips(INPUT_AUDIO, sentences, OUTPUT_DIR, fmt=\"wav\")\n",
        "print(f\"\\n✅ Saved {len(saved)} sentence clips to: {OUTPUT_DIR}\")\n",
        "print(\"Example files:\")\n",
        "print(\"\\n\".join(saved[:5]))\n"
      ],
      "metadata": {
        "id": "QShtA_21RfLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6301f0-8923-40bc-cd82-df519e9a6fdc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "BASIC SPEECH RECOGNITION + SENTENCE SPLITTING + CLIP SAVING\n",
            "==================================================\n",
            "🎙️ Starting transcribe with Whisper...\n",
            "   Language: auto-detect\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14317/14317 [00:54<00:00, 264.63frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Saved 27 sentence clips to: /content/sentences_out\n",
            "Example files:\n",
            "/content/sentences_out/001_00-00-00_00-00-04_In this video were going to cover how to.wav\n",
            "/content/sentences_out/002_00-00-05_00-00-08_Now you can see we both have a little mi.wav\n",
            "/content/sentences_out/003_00-00-09_00-00-17_Were running them into a Y splitter and.wav\n",
            "/content/sentences_out/004_00-00-18_00-00-22_So I have with me today my guest is Keit.wav\n",
            "/content/sentences_out/005_00-00-22_00-00-23_Keith could you tell us a little bit abo.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install resemblyzer soundfile librosa scikit-learn joblib\n",
        "\n",
        "import os, glob, numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from pathlib import Path\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from joblib import dump, load\n"
      ],
      "metadata": {
        "id": "NvBDn4ctRfGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca15371-1cef-436f-8344-c10cdbd96bcb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 要解压到的目标文件夹\n",
        "os.makedirs(\"/content/VOICE\", exist_ok=True)\n",
        "\n",
        "\n",
        "# 解压 VOICE.zip\n",
        "with zipfile.ZipFile(\"/content/VOICE.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/VOICE\")\n",
        "\n",
        "\n",
        "print(\"✅ 解压完成\")\n"
      ],
      "metadata": {
        "id": "gdfNEcPsRfDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c0eb95-3212-43dc-968c-621e6d449437"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 解压完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = Path(\"/content/VOICE/VOICE\")\n",
        "A_DIR = ROOT / \"A\"\n",
        "B_DIR = ROOT / \"B\"\n",
        "assert A_DIR.exists() and B_DIR.exists(), \"Make sure you already moved files into A/ and B/\"\n"
      ],
      "metadata": {
        "id": "WHMD3GDIRfBA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = VoiceEncoder()  # CPU is fine; it'll just be slower\n",
        "\n",
        "import librosa, soundfile as sf\n",
        "import numpy as np\n",
        "from resemblyzer import VoiceEncoder\n",
        "\n",
        "encoder = VoiceEncoder()\n",
        "\n",
        "def file_to_embedding(path: Path, target_sr=16000, min_len_sec=1.0):\n",
        "    # 读文件，不用VAD\n",
        "    sig, sr = sf.read(str(path), always_2d=False)\n",
        "    if sig.ndim > 1:\n",
        "        sig = sig.mean(axis=1)\n",
        "    if sr != target_sr:\n",
        "        sig = librosa.resample(sig.astype(np.float32), orig_sr=sr, target_sr=target_sr)\n",
        "    else:\n",
        "        sig = sig.astype(np.float32)\n",
        "\n",
        "    # 正常化\n",
        "    m = np.max(np.abs(sig)) or 1.0\n",
        "    sig = sig / m\n",
        "\n",
        "    # 补零到至少 min_len_sec\n",
        "    min_len = int(min_len_sec * target_sr)\n",
        "    if len(sig) < min_len:\n",
        "        sig = np.pad(sig, (0, min_len - len(sig)))\n",
        "\n",
        "    emb = encoder.embed_utterance(sig)\n",
        "    return emb.astype(np.float32)\n",
        "\n"
      ],
      "metadata": {
        "id": "D6Yuq_gjRe-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e26b2c-aee7-4f4d-97ed-ee4b6568911e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, fnames = [], [], []\n",
        "\n",
        "for label, d in [(0, A_DIR), (1, B_DIR)]:\n",
        "    for f in sorted(glob.glob(str(d / \"*\"))):\n",
        "        emb = file_to_embedding(Path(f))\n",
        "        if emb is None:\n",
        "            continue\n",
        "        X.append(emb); y.append(label); fnames.append(f)\n",
        "\n",
        "X = np.vstack(X)\n",
        "y = np.array(y)\n",
        "print(\"Embeddings:\", X.shape, \" A:\", (y==0).sum(), \" B:\", (y==1).sum())\n"
      ],
      "metadata": {
        "id": "rUopYa9-Re6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f612beca-031b-4919-f5b7-42c3e9c04d54"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings: (6, 256)  A: 3  B: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Pipeline: standardize → classifier\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=2000, n_jobs=1)\n",
        ")\n",
        "# Alternative:\n",
        "# clf = make_pipeline(StandardScaler(), SVC(kernel=\"linear\", probability=True))\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Train acc:\", clf.score(X_train, y_train))\n",
        "print(\"Test  acc:\", clf.score(X_test, y_test))\n",
        "\n",
        "# Quick CV check (optional)\n",
        "scores = cross_val_score(clf, X, y, cv=3)\n",
        "print(\"3-fold CV acc:\", scores.mean().round(4), \"±\", scores.std().round(4))\n",
        "\n",
        "# Save model + label map\n",
        "dump(clf, ROOT / \"ab_classifier.joblib\")\n",
        "np.save(ROOT / \"label_map.npy\", np.array([\"A\",\"B\"]))\n",
        "print(\"✅ Saved:\", ROOT / \"ab_classifier.joblib\")\n"
      ],
      "metadata": {
        "id": "TBb42AZvRe3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fbc79b-dda4-4a26-c108-f4901d2f095d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 1.0\n",
            "Test  acc: 1.0\n",
            "3-fold CV acc: 1.0 ± 0.0\n",
            "✅ Saved: /content/sentences_out/ab_classifier.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 批量自动标注 sentences_out 下的音频（A/B）====\n",
        "import os, glob, csv, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from joblib import load\n",
        "\n",
        "# -------- 路径配置 --------\n",
        "ROOT = Path(\"/content/sentences_out\")        # 你的音频根目录\n",
        "MODEL_PATH = ROOT / \"ab_classifier.joblib\"   # 上一步保存的模型\n",
        "LABEL_MAP_PATH = ROOT / \"label_map.npy\"      # 上一步保存的 label map\n",
        "\n",
        "# 是否把文件移动到 A/ B/（低置信度移到 Uncertain/），否则只写 CSV\n",
        "MOVE_FILES = True\n",
        "CONF_THRESH = 0.60                           # 低于这个就标为不确定\n",
        "\n",
        "# -------- 读取模型与标签名 --------\n",
        "clf = load(MODEL_PATH)\n",
        "label_map = np.load(LABEL_MAP_PATH)\n",
        "\n",
        "# -------- 和训练时一致的嵌入函数（无VAD，短句补零到>=1s）--------\n",
        "from resemblyzer import VoiceEncoder\n",
        "encoder = VoiceEncoder()\n",
        "\n",
        "def file_to_embedding(path: Path, target_sr=16000, min_len_sec=1.0):\n",
        "    sig, sr = sf.read(str(path), always_2d=False)\n",
        "    if sig.ndim > 1:\n",
        "        sig = sig.mean(axis=1)\n",
        "    if sr != target_sr:\n",
        "        sig = librosa.resample(sig.astype(np.float32), orig_sr=sr, target_sr=target_sr)\n",
        "    else:\n",
        "        sig = sig.astype(np.float32)\n",
        "    m = np.max(np.abs(sig)) or 1.0\n",
        "    sig = sig / m\n",
        "    min_len = int(min_len_sec * target_sr)\n",
        "    if len(sig) < min_len:\n",
        "        sig = np.pad(sig, (0, min_len - len(sig)))\n",
        "    emb = encoder.embed_utterance(sig)\n",
        "    return emb.astype(np.float32)\n",
        "\n",
        "# -------- 收集待预测文件（排除 A/ B/ 子目录和已移动的文件）--------\n",
        "EXTS = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\"}\n",
        "def list_audio(root: Path):\n",
        "    files = []\n",
        "    for p in root.iterdir():\n",
        "        if p.is_dir() and p.name in {\"A\",\"B\",\"Uncertain\"}:\n",
        "            continue\n",
        "        if p.is_file() and p.suffix.lower() in EXTS:\n",
        "            files.append(p)\n",
        "    return sorted(files)\n",
        "\n",
        "files = list_audio(ROOT)\n",
        "print(f\"Found {len(files)} files to label.\")\n",
        "\n",
        "# -------- 预测并（可选）移动 --------\n",
        "pred_rows = []\n",
        "(A_DIR, B_DIR, U_DIR) = (ROOT/\"A_LABEL\", ROOT/\"B_LABEL\", ROOT/\"Uncertain\")\n",
        "if MOVE_FILES:\n",
        "    A_DIR.mkdir(exist_ok=True); B_DIR.mkdir(exist_ok=True); U_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "for f in files:\n",
        "    try:\n",
        "        emb = file_to_embedding(f)\n",
        "        proba = clf.predict_proba([emb])[0]\n",
        "        idx = int(np.argmax(proba))\n",
        "        pred = str(label_map[idx])\n",
        "        conf = float(proba[idx])\n",
        "\n",
        "        # 低置信度 → 不确定\n",
        "        final_label = pred if conf >= CONF_THRESH else \"Uncertain\"\n",
        "\n",
        "        # 记录\n",
        "        pred_rows.append({\n",
        "            \"filename\": f.name,\n",
        "            \"path\": str(f),\n",
        "            \"pred\": pred,\n",
        "            \"confidence\": round(conf, 4),\n",
        "            \"final_label\": final_label\n",
        "        })\n",
        "\n",
        "        # 移动\n",
        "        if MOVE_FILES:\n",
        "            if final_label == \"A\":\n",
        "                dst_dir = A_DIR\n",
        "            elif final_label == \"B\":\n",
        "                dst_dir = B_DIR\n",
        "            else:\n",
        "                dst_dir = U_DIR\n",
        "\n",
        "            dst = dst_dir / f.name\n",
        "            if dst.exists():  # 防覆盖\n",
        "                base, ext = os.path.splitext(f.name)\n",
        "                k = 1\n",
        "                while (dst_dir / f\"{base}_{k}{ext}\").exists():\n",
        "                    k += 1\n",
        "                dst = dst_dir / f\"{base}_{k}{ext}\"\n",
        "            shutil.move(str(f), str(dst))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ {f.name} failed: {e}\")\n",
        "\n",
        "# -------- 写出 CSV --------\n",
        "CSV_PATH = ROOT / \"predictions.csv\"\n",
        "with open(CSV_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\"filename\",\"path\",\"pred\",\"confidence\",\"final_label\"])\n",
        "    w.writeheader()\n",
        "    w.writerows(pred_rows)\n",
        "\n",
        "print(f\"✅ Done. Wrote predictions to: {CSV_PATH}\")\n",
        "if MOVE_FILES:\n",
        "    print(f\"Files moved to: {A_DIR}, {B_DIR}, and {U_DIR} (if low confidence).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGn_dTfU2JA2",
        "outputId": "717d3fb8-62bc-4669-d4f8-d8a95b24c44f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Found 27 files to label.\n",
            "✅ Done. Wrote predictions to: /content/sentences_out/predictions.csv\n",
            "Files moved to: /content/sentences_out/A_LABEL, /content/sentences_out/B_LABEL, and /content/sentences_out/Uncertain (if low confidence).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, glob\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/sentences_out\")\n",
        "A_DIR, B_DIR = ROOT/\"A_LABEL\", ROOT/\"B_LABEL\"\n",
        "\n",
        "# 1) 建立 “时间戳片段字符串 -> 标签” 的索引（用文件名里的 00-00-05_00-00-08 片段匹配）\n",
        "def build_time_to_label():\n",
        "    time2lab = {}\n",
        "    rx = re.compile(r\"(\\d{2}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2})\")  # 例如 00-00-05_00-00-08\n",
        "    for lab, d in [(\"A\", A_DIR), (\"B\", B_DIR)]:\n",
        "        for f in glob.glob(str(d/\"*\")):\n",
        "            m = rx.search(os.path.basename(f))\n",
        "            if m:\n",
        "                time2lab[m.group(1)] = lab\n",
        "    return time2lab\n",
        "\n",
        "time2lab = build_time_to_label()\n",
        "\n",
        "\n",
        "# 2) 处理你的转写文本（把下面这段换成你实际的字符串或读取文件）\n",
        "transcript = \"\"\"=== Formatted (one sentence per segment) ===\n",
        "[00:00:00] Speaker_A: video we're going to cover how to do an interview with the host and a guest on camera at the same time.\n",
        "[00:00:05] Speaker_A: Now you can see we both have a little microphone on this, a lavalier microphone.\n",
        "[00:00:09] Speaker_A: We're running them into a Y splitter and then from that we're going into that KD connector that goes into the iPad, the iPhone, or whatever you're recording into.\n",
        "[00:00:18] Speaker_A: So I have with me today my guest is Keith Gilmore.\n",
        "[00:00:22] Speaker_A: Keith, could you tell us a little bit about yourself?\n",
        "[00:00:24] Speaker_A: Yeah, but a copywriter for the last seven years and basically helped to make the create the best messages that are the most compelling for my clients.\n",
        "[00:00:37] Speaker_A: So a copywriting thing is not a legal thing, it's more of a sales marketing.\n",
        "[00:00:39] Speaker_A: No, it's not the marketing scene with a little circle around it.\n",
        "[00:00:44] Speaker_A: Yeah, it's along the lines of all things marketing.\n",
        "[00:00:48] Speaker_A: Great, well thank you.\n",
        "[00:00:50] Speaker_A: So one of the things we're checking right here is the volume of how he speaks and how I speak and making sure we have some rhythm and before we really get into the meat of what we're going to be talking about, we're just having some banter back and forth.\n",
        "[00:01:02] Speaker_A: So we're checking our audio levels and that as he's talking or I'm talking, I'm not talking, then I kind of drop off and stuff like that.\n",
        "[00:01:10] Speaker_A: You want to make sure that you're both speaking loud and clear and that if you do have a VU meter or that meter, you're not peeking into the red, you're staying with the top of that green and into the yellow of using say, Filmic Pro.\n",
        "[00:01:22] Speaker_A: That's what we really like to do is make sure you have a nice strong signal.\n",
        "[00:01:26] Speaker_A: So even though we're very close together here, we're about, what would you say, maybe 18 inches or two feet apart?\n",
        "[00:01:32] Speaker_A: No, it's really, I'm talking past him, he's talking past me.\n",
        "[00:01:37] Speaker_A: It's not like a just a quiet conversation we'd have if we were actually this close.\n",
        "[00:01:42] Speaker_A: The other thing is he and I are sitting relatively close, but on TV, it always looks like people are further apart.\n",
        "[00:01:49] Speaker_A: So I'm actually, I have my legs crossed and I,\n",
        "[00:01:52] Speaker_A: this is normally we would sit this close together.\n",
        "[00:01:55] Speaker_A: This is kind of uncomfortable, but on camera, it doesn't look so bad.\n",
        "[00:01:58] Speaker_A: So let's do one more test for the audio and we'll make sure that both the volume of what I'm speaking and here is speaking is relatively the same.\n",
        "[00:02:09] Speaker_A: So Keith, could you tell us a little bit about copywriting?\n",
        "[00:02:12] Speaker_A: What is what is one thing that people really need to think about when they are having to look at good copy or right good copy?\n",
        "[00:02:20] Speaker_A: Sure, always think about who you're writing to.\n",
        "\"\"\"\n",
        "\n",
        "# 3) 给每行前面加 A/B 标签：用方括号时间戳匹配文件名里的时间片\n",
        "def hhmmss_to_key(hms):\n",
        "    # [00:00:05] -> 00-00-05_00-00-08  但我们只知道“开始时间”\n",
        "    # 用“开始时间”模糊匹配：任何文件名里包含 00-00-05_ 都算匹配\n",
        "    return hms.replace(\":\", \"-\") + \"_\"\n",
        "\n",
        "out_lines = []\n",
        "ts_re = re.compile(r\"^\\[(\\d{2}:\\d{2}:\\d{2})\\]\\s+\")\n",
        "for line in transcript.splitlines():\n",
        "    m = ts_re.match(line)\n",
        "    if not m:\n",
        "        out_lines.append(line)\n",
        "        continue\n",
        "    start = m.group(1)\n",
        "    key_prefix = hhmmss_to_key(start)  # 例如 00-00-05_\n",
        "    # 在 time2lab 里找以该前缀开头的键\n",
        "    lab = None\n",
        "    for k, v in time2lab.items():\n",
        "        if k.startswith(key_prefix):\n",
        "            lab = v\n",
        "            break\n",
        "    lab = lab or \"?\"  # 找不到就打 ?\n",
        "    out_lines.append(f\"[{lab}] {line}\")\n",
        "\n",
        "labeled_text = \"\\n\".join(out_lines)\n",
        "print(labeled_text)\n",
        "\n",
        "# 保存到文件\n",
        "(Path(\"/content\")/\"labeled_transcript.txt\").write_text(labeled_text, encoding=\"utf-8\")\n",
        "print(\"✅ 写入 /content/labeled_transcript.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMp4b7MU2I9d",
        "outputId": "0d3d3a5e-7ad7-4754-b184-8ee98ef96466"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Formatted (one sentence per segment) ===\n",
            "[A] [00:00:00] Speaker_A: video we're going to cover how to do an interview with the host and a guest on camera at the same time.\n",
            "[A] [00:00:05] Speaker_A: Now you can see we both have a little microphone on this, a lavalier microphone.\n",
            "[A] [00:00:09] Speaker_A: We're running them into a Y splitter and then from that we're going into that KD connector that goes into the iPad, the iPhone, or whatever you're recording into.\n",
            "[?] [00:00:18] Speaker_A: So I have with me today my guest is Keith Gilmore.\n",
            "[B] [00:00:22] Speaker_A: Keith, could you tell us a little bit about yourself?\n",
            "[B] [00:00:24] Speaker_A: Yeah, but a copywriter for the last seven years and basically helped to make the create the best messages that are the most compelling for my clients.\n",
            "[A] [00:00:37] Speaker_A: So a copywriting thing is not a legal thing, it's more of a sales marketing.\n",
            "[B] [00:00:39] Speaker_A: No, it's not the marketing scene with a little circle around it.\n",
            "[B] [00:00:44] Speaker_A: Yeah, it's along the lines of all things marketing.\n",
            "[B] [00:00:48] Speaker_A: Great, well thank you.\n",
            "[?] [00:00:50] Speaker_A: So one of the things we're checking right here is the volume of how he speaks and how I speak and making sure we have some rhythm and before we really get into the meat of what we're going to be talking about, we're just having some banter back and forth.\n",
            "[?] [00:01:02] Speaker_A: So we're checking our audio levels and that as he's talking or I'm talking, I'm not talking, then I kind of drop off and stuff like that.\n",
            "[A] [00:01:10] Speaker_A: You want to make sure that you're both speaking loud and clear and that if you do have a VU meter or that meter, you're not peeking into the red, you're staying with the top of that green and into the yellow of using say, Filmic Pro.\n",
            "[?] [00:01:22] Speaker_A: That's what we really like to do is make sure you have a nice strong signal.\n",
            "[A] [00:01:26] Speaker_A: So even though we're very close together here, we're about, what would you say, maybe 18 inches or two feet apart?\n",
            "[B] [00:01:32] Speaker_A: No, it's really, I'm talking past him, he's talking past me.\n",
            "[A] [00:01:37] Speaker_A: It's not like a just a quiet conversation we'd have if we were actually this close.\n",
            "[A] [00:01:42] Speaker_A: The other thing is he and I are sitting relatively close, but on TV, it always looks like people are further apart.\n",
            "[?] [00:01:49] Speaker_A: So I'm actually, I have my legs crossed and I,\n",
            "[?] [00:01:52] Speaker_A: this is normally we would sit this close together.\n",
            "[A] [00:01:55] Speaker_A: This is kind of uncomfortable, but on camera, it doesn't look so bad.\n",
            "[?] [00:01:58] Speaker_A: So let's do one more test for the audio and we'll make sure that both the volume of what I'm speaking and here is speaking is relatively the same.\n",
            "[A] [00:02:09] Speaker_A: So Keith, could you tell us a little bit about copywriting?\n",
            "[A] [00:02:12] Speaker_A: What is what is one thing that people really need to think about when they are having to look at good copy or right good copy?\n",
            "[B] [00:02:20] Speaker_A: Sure, always think about who you're writing to.\n",
            "✅ 写入 /content/labeled_transcript.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "IN_PATH  = \"/content/labeled_transcript.txt\"       # 你的当前结果\n",
        "#OUT_PATH = \"/content/labeled_transcript_spk.txt\"   # 目标输出\n",
        "\n",
        "\n",
        "# 读文件 → 拆行\n",
        "text  = Path(IN_PATH).read_text(encoding=\"utf-8\")\n",
        "lines = text.splitlines()\n",
        "\n",
        "rx = re.compile(r'^\\[(?P<lab>[AB?])\\]\\s+\\[(?P<ts>\\d{2}:\\d{2}:\\d{2})\\]\\s*(?P<rest>.*)$')\n",
        "strip_spk = re.compile(r'^\\s*Speaker_[A-Za-z]\\s*:\\s*')\n",
        "\n",
        "for ln in lines:\n",
        "    m = rx.match(ln)\n",
        "    if not m:\n",
        "        print(ln)                     # 比如标题行会原样输出\n",
        "        continue\n",
        "    lab  = m.group(\"lab\")\n",
        "    ts   = m.group(\"ts\")\n",
        "    rest = strip_spk.sub(\"\", m.group(\"rest\"))\n",
        "\n",
        "    speaker = \"Speaker_A\" if lab==\"A\" else (\"Speaker_B\" if lab==\"B\" else \"Speaker_?\")\n",
        "    print(f\"[{ts}] {speaker}: {rest}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmyeH5Je2I7R",
        "outputId": "1b33037c-29c3-49e1-ca39-f14868fa609c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Formatted (one sentence per segment) ===\n",
            "[00:00:00] Speaker_A: video we're going to cover how to do an interview with the host and a guest on camera at the same time.\n",
            "[00:00:05] Speaker_A: Now you can see we both have a little microphone on this, a lavalier microphone.\n",
            "[00:00:09] Speaker_A: We're running them into a Y splitter and then from that we're going into that KD connector that goes into the iPad, the iPhone, or whatever you're recording into.\n",
            "[00:00:18] Speaker_?: So I have with me today my guest is Keith Gilmore.\n",
            "[00:00:22] Speaker_B: Keith, could you tell us a little bit about yourself?\n",
            "[00:00:24] Speaker_B: Yeah, but a copywriter for the last seven years and basically helped to make the create the best messages that are the most compelling for my clients.\n",
            "[00:00:37] Speaker_A: So a copywriting thing is not a legal thing, it's more of a sales marketing.\n",
            "[00:00:39] Speaker_B: No, it's not the marketing scene with a little circle around it.\n",
            "[00:00:44] Speaker_B: Yeah, it's along the lines of all things marketing.\n",
            "[00:00:48] Speaker_B: Great, well thank you.\n",
            "[00:00:50] Speaker_?: So one of the things we're checking right here is the volume of how he speaks and how I speak and making sure we have some rhythm and before we really get into the meat of what we're going to be talking about, we're just having some banter back and forth.\n",
            "[00:01:02] Speaker_?: So we're checking our audio levels and that as he's talking or I'm talking, I'm not talking, then I kind of drop off and stuff like that.\n",
            "[00:01:10] Speaker_A: You want to make sure that you're both speaking loud and clear and that if you do have a VU meter or that meter, you're not peeking into the red, you're staying with the top of that green and into the yellow of using say, Filmic Pro.\n",
            "[00:01:22] Speaker_?: That's what we really like to do is make sure you have a nice strong signal.\n",
            "[00:01:26] Speaker_A: So even though we're very close together here, we're about, what would you say, maybe 18 inches or two feet apart?\n",
            "[00:01:32] Speaker_B: No, it's really, I'm talking past him, he's talking past me.\n",
            "[00:01:37] Speaker_A: It's not like a just a quiet conversation we'd have if we were actually this close.\n",
            "[00:01:42] Speaker_A: The other thing is he and I are sitting relatively close, but on TV, it always looks like people are further apart.\n",
            "[00:01:49] Speaker_?: So I'm actually, I have my legs crossed and I,\n",
            "[00:01:52] Speaker_?: this is normally we would sit this close together.\n",
            "[00:01:55] Speaker_A: This is kind of uncomfortable, but on camera, it doesn't look so bad.\n",
            "[00:01:58] Speaker_?: So let's do one more test for the audio and we'll make sure that both the volume of what I'm speaking and here is speaking is relatively the same.\n",
            "[00:02:09] Speaker_A: So Keith, could you tell us a little bit about copywriting?\n",
            "[00:02:12] Speaker_A: What is what is one thing that people really need to think about when they are having to look at good copy or right good copy?\n",
            "[00:02:20] Speaker_B: Sure, always think about who you're writing to.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part3\n"
      ],
      "metadata": {
        "id": "CcLFriu84Lsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path_03 = extract_audio(\"video03.mp4\")\n",
        "\n",
        "# Try to load sample audio\n",
        "try:\n",
        "\n",
        "    audio_data, sample_rate = load_and_preprocess_audio(audio_path_03)\n",
        "    audio_source = \"Downloaded sample video03\"\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Download failed: {e}\")\n",
        "    print(\"Creating synthetic speech-like signal for demonstration...\")\n",
        "\n",
        "    # Create a synthetic audio signal that resembles speech patterns\n",
        "    sample_rate = 16000\n",
        "    duration = 3.0\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Create a signal with speech-like characteristics\n",
        "    # Combine multiple frequencies to simulate formants\n",
        "    signal = (0.3 * np.sin(2 * np.pi * 200 * t) +  # F1 (low frequency)\n",
        "              0.2 * np.sin(2 * np.pi * 1000 * t) +  # F2 (mid frequency)\n",
        "              0.1 * np.sin(2 * np.pi * 2500 * t))   # F3 (high frequency)\n",
        "\n",
        "    # Add some amplitude modulation to simulate speech rhythm\n",
        "    envelope = 0.5 * (1 + np.sin(2 * np.pi * 3 * t))\n",
        "    audio_data = signal * envelope\n",
        "\n",
        "    # Normalize\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iSofoLf7x_-",
        "outputId": "97fcc412-9270-4292-eb80-16c601eff87c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in video03.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "音频提取完成，保存为：video03.wav\n",
            "✅ Loaded audio: video03.wav\n",
            "   Original shape: torch.Size([2, 4015305])\n",
            "   Original sample rate: 44100 Hz\n",
            "   Duration: 91.05 seconds\n",
            "   Converted to mono\n",
            "   Resampled to 16000 Hz\n",
            "   Final shape: torch.Size([1, 1456800])\n",
            "   Audio range: [-1.000, 0.950]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    Do Whisper transcription WITH timestamps so we can merge later.\n",
        "    \"\"\"\n",
        "    print(f\"🎙️ Starting {task} with Whisper...\")\n",
        "    print(f\"   Language: {language if language else 'auto-detect'}\")\n",
        "    print(f\"   Audio duration: {len(audio_data)/16000:.2f} seconds\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_data,\n",
        "        language=language,\n",
        "        task=task,\n",
        "        verbose=False,\n",
        "        word_timestamps=True,      # <— 关键：拿词级时间戳\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_into_sentences(result, max_gap=0.8):\n",
        "    \"\"\"\n",
        "    把 Whisper 输出合并成“每段=完整一句话”。\n",
        "    优先用词级时间戳重建；没有则按段合并。\n",
        "    max_gap: 同一句里允许的最大相邻词静音间隔（秒）\n",
        "    \"\"\"\n",
        "    sentence_end = re.compile(r'[.!?…]+$')\n",
        "    merged = []\n",
        "\n",
        "    # --- 跑词级方案 ---\n",
        "    has_words = any('words' in s and s['words'] for s in result.get('segments', []))\n",
        "    if has_words:\n",
        "        cur_words = []\n",
        "        for seg in result['segments']:\n",
        "            for w in seg.get('words', []):\n",
        "                # w = {'word': 'Hello', 'start': 0.1, 'end': 0.5}\n",
        "                if not cur_words:\n",
        "                    cur_words.append(w)\n",
        "                    continue\n",
        "\n",
        "                gap = w['start'] - cur_words[-1]['end']\n",
        "                # 条件1：遇到句末标点；条件2：静音间隔太长——都认为要“收句”\n",
        "                if sentence_end.search(cur_words[-1]['word'].strip()) or gap > max_gap:\n",
        "                    text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "                    merged.append({\n",
        "                        'start': cur_words[0]['start'],\n",
        "                        'end':   cur_words[-1]['end'],\n",
        "                        'text':  re.sub(r'\\s+', ' ', text)\n",
        "                    })\n",
        "                    cur_words = [w]\n",
        "                else:\n",
        "                    cur_words.append(w)\n",
        "\n",
        "        if cur_words:\n",
        "            text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "            merged.append({\n",
        "                'start': cur_words[0]['start'],\n",
        "                'end':   cur_words[-1]['end'],\n",
        "                'text':  re.sub(r'\\s+', ' ', text)\n",
        "            })\n",
        "        return merged\n",
        "\n",
        "    # --- 退化：按段合并 ---\n",
        "    cur = None\n",
        "    for seg in result.get('segments', []):\n",
        "        if cur is None:\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "            continue\n",
        "\n",
        "        gap = seg['start'] - cur['end']\n",
        "        if sentence_end.search(cur['text']) or gap > max_gap:\n",
        "            merged.append(cur)\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "        else:\n",
        "            cur['end'] = seg['end']\n",
        "            cur['text'] = (cur['text'] + ' ' + seg['text']).strip()\n",
        "\n",
        "    if cur:\n",
        "        merged.append(cur)\n",
        "    return merged\n",
        "\n",
        "\n",
        "# ---------- 用法 ----------\n",
        "print(\"=\" * 50)\n",
        "print(\"BASIC SPEECH RECOGNITION\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "result = transcribe_with_whisper(model, audio_data, language=None, task=\"transcribe\")\n",
        "\n",
        "print(\"\\n📝 Transcription Results:\")\n",
        "print(f\"Detected language: {result.get('language', 'unknown')}\")\n",
        "print(f\"Transcript (raw): '{result.get('text','').strip()}'\")\n",
        "\n",
        "sentences = merge_into_sentences(result, max_gap=0.8)\n",
        "\n",
        "def hhmmss(t):\n",
        "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "print(\"\\n=== Formatted (one sentence per segment) ===\")\n",
        "for s in sentences:\n",
        "    print(f\"[{hhmmss(s['start'])}] {s['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQDyKk3GXhN",
        "outputId": "58349265-533d-48bd-9075-c8bae01b60ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "BASIC SPEECH RECOGNITION\n",
            "==================================================\n",
            "🎙️ Starting transcribe with Whisper...\n",
            "   Language: auto-detect\n",
            "   Audio duration: 91.05 seconds\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9105/9105 [01:00<00:00, 151.59frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Transcription Results:\n",
            "Detected language: en\n",
            "Transcript (raw): 'How many languages do you speak? It depends what you mean by speak. So I've gotten pretty rusty in my Arabic and my Dari, which picked up Dari on my way to Afghanistan. I can still kind of read a newspaper in Norwegian, but only slow. I'm a little bit dizzy from South Bend, Indiana. I want to tell you more about the French language. We share the pain today, that the fourth of our life was like a fourth to the special. I'm a Sa'hlan and I'm a Pete Buttigieg. I'm a lady in South Bend, Indiana. I want to be a sense of inclusion in our country. Not only in the immigration issue, but in all economic institutions, in all security institutions, which we are together. Salam, Pete Buttigieg, I'm here. Yes, I'm here. But all the perspectives are very, very important. I'm not going to ask you to speak in the language. No, no. I'm not going to speak in the language. Sorry, I'm out of the telling dude. Salam, Pete Buttigieg has done. I'm going to go to the office. What do you want to do now? I'm going to go to the office. I'm going to go to the office. We're going to go to the office. We've got a company that's going to be working on the US. We've got some other places. Just someone or someone. They're at this round out of nowhere. It was very good. I bet.'\n",
            "\n",
            "=== Formatted (one sentence per segment) ===\n",
            "[00:00:00] How many languages do you speak?\n",
            "[00:00:02] It depends what you mean by speak.\n",
            "[00:00:04] So I've gotten pretty rusty in my Arabic and my Dari, which picked up Dari on my way to Afghanistan.\n",
            "[00:00:10] I can still kind of read a newspaper in Norwegian, but only slow.\n",
            "[00:00:14] I'm a little bit dizzy from South Bend, Indiana.\n",
            "[00:00:17] I want to tell you more about the French language.\n",
            "[00:00:19] We share the pain today,\n",
            "[00:00:22] that the fourth of our life was like a fourth to the special.\n",
            "[00:00:27] I'm a Sa 'hlan and I'm a Pete Buttigieg.\n",
            "[00:00:30] I'm a lady in South Bend, Indiana.\n",
            "[00:00:33] I want to be a sense of inclusion in our country.\n",
            "[00:00:37] Not only in the immigration issue, but in all economic institutions, in all security institutions, which we are together.\n",
            "[00:00:47] Salam, Pete Buttigieg, I'm here.\n",
            "[00:00:49] Yes, I'm here.\n",
            "[00:00:51] But all the perspectives are very, very important.\n",
            "[00:00:57] I'm not going to ask you to speak in the language.\n",
            "[00:00:59] No, no.\n",
            "[00:01:00] I'm not going to speak in the language.\n",
            "[00:01:02] Sorry, I'm out of the telling dude.\n",
            "[00:01:03] Salam, Pete Buttigieg has done.\n",
            "[00:01:05] I'm going to go to the office.\n",
            "[00:01:07] What do you want to do now?\n",
            "[00:01:09] I'm going to go to the office.\n",
            "[00:01:13] I'm going to go to the office.\n",
            "[00:01:15] We're going to go to the office.\n",
            "[00:01:18] We've got a company that's going to be working on the US.\n",
            "[00:01:22] We've got some other places.\n",
            "[00:01:24] Just someone or someone.\n",
            "[00:01:26] They're at this round out of nowhere.\n",
            "[00:01:28] It was very good.\n",
            "[00:01:29] I bet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFXYrogGATnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- (一次性) 依赖安装：在 Colab 可直接运行 ---\n",
        "# !pip -q install pydub openai-whisper\n",
        "\n",
        "import os, re, unicodedata, math\n",
        "from pathlib import Path\n",
        "from pydub import AudioSegment\n",
        "\n",
        "try:\n",
        "    import whisper  # 如果你已有 model 对象，可以忽略加载\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# ============== 配置区（根据你的情况修改） ==============\n",
        "# 1) 如果你从“文件”开始，填路径（常见）：\n",
        "INPUT_AUDIO = \"/content/video03.wav\"   # 支持 wav/mp3/m4a 等\n",
        "OUTPUT_DIR  = \"/content/video3/sentences_out\"\n",
        "\n",
        "# 2) 如果你已经有 whisper 的 model 和 audio_data，可把下面两行设为 None，并使用你现成的对象\n",
        "MODEL_SIZE  = \"base\"   # tiny/base/small/medium/large (根据你的显存和速度选择)\n",
        "USE_FILE_INPUT = True  # True：走文件路径；False：使用你现成的 audio_data 变量\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "def load_whisper_model(name=\"base\"):\n",
        "    print(f\"🚀 Loading Whisper model: {name}\")\n",
        "    return whisper.load_model(name)\n",
        "\n",
        "\n",
        "def transcribe_with_whisper(model, audio_source, language=None, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    audio_source: 如果是 numpy 数组(16k 单声道)就直接传数组；如果是路径就传 str/path。\n",
        "    \"\"\"\n",
        "    print(f\"🎙️ Starting {task} with Whisper...\")\n",
        "    print(f\"   Language: {language if language else 'auto-detect'}\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_source,\n",
        "        language=language,\n",
        "        task=task,\n",
        "        verbose=False,\n",
        "        word_timestamps=True,      # 关键：拿词级时间戳\n",
        "        condition_on_previous_text=True\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def merge_into_sentences(result, max_gap=0.8):\n",
        "    \"\"\"\n",
        "    把 Whisper 输出合并成“每段=完整一句话”。\n",
        "    优先用词级时间戳重建；没有则按段合并。\n",
        "    max_gap: 同一句里允许的最大相邻词静音间隔（秒）\n",
        "    \"\"\"\n",
        "    sentence_end = re.compile(r'[.!?…]+$')\n",
        "    merged = []\n",
        "\n",
        "    # --- 跑词级方案 ---\n",
        "    has_words = any('words' in s and s['words'] for s in result.get('segments', []))\n",
        "    if has_words:\n",
        "        cur_words = []\n",
        "        for seg in result['segments']:\n",
        "            for w in seg.get('words', []):\n",
        "                # w = {'word': 'Hello', 'start': 0.1, 'end': 0.5}\n",
        "                if not cur_words:\n",
        "                    cur_words.append(w)\n",
        "                    continue\n",
        "\n",
        "                gap = w['start'] - cur_words[-1]['end']\n",
        "                # 条件1：遇到句末标点；条件2：静音间隔太长——都认为要“收句”\n",
        "                if sentence_end.search(cur_words[-1]['word'].strip()) or gap > max_gap:\n",
        "                    text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "                    merged.append({\n",
        "                        'start': cur_words[0]['start'],\n",
        "                        'end':   cur_words[-1]['end'],\n",
        "                        'text':  re.sub(r'\\s+', ' ', text)\n",
        "                    })\n",
        "                    cur_words = [w]\n",
        "                else:\n",
        "                    cur_words.append(w)\n",
        "\n",
        "        if cur_words:\n",
        "            text = \" \".join(x['word'] for x in cur_words).strip()\n",
        "            merged.append({\n",
        "                'start': cur_words[0]['start'],\n",
        "                'end':   cur_words[-1]['end'],\n",
        "                'text':  re.sub(r'\\s+', ' ', text)\n",
        "            })\n",
        "        return merged\n",
        "\n",
        "    # --- 退化：按段合并 ---\n",
        "    cur = None\n",
        "    for seg in result.get('segments', []):\n",
        "        if cur is None:\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "            continue\n",
        "\n",
        "        gap = seg['start'] - cur['end']\n",
        "        if sentence_end.search(cur['text']) or gap > max_gap:\n",
        "            merged.append(cur)\n",
        "            cur = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'].strip()}\n",
        "        else:\n",
        "            cur['end'] = seg['end']\n",
        "            cur['text'] = (cur['text'] + ' ' + seg['text']).strip()\n",
        "\n",
        "    if cur:\n",
        "        merged.append(cur)\n",
        "    return merged\n",
        "\n",
        "\n",
        "def hhmmss(t):\n",
        "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "\n",
        "def save_sentence_clips(input_audio_path, sentences, out_dir, fmt=\"wav\",\n",
        "                        head_pad=0.20, tail_pad=0.35, guard_next=0.05):\n",
        "    \"\"\"\n",
        "    head_pad/tail_pad: 每句前后额外保留的秒数，防止被切早/切晚\n",
        "    guard_next: 句尾最多到下一句开始前留一点点缝(避免重叠爆音)\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    audio = AudioSegment.from_file(input_audio_path)\n",
        "    dur = audio.duration_seconds\n",
        "\n",
        "    saved_files = []\n",
        "    for i, s in enumerate(sentences, start=1):\n",
        "        # 目标起止（加上缓冲）\n",
        "        start = max(0.0, s['start'] - head_pad)\n",
        "        end   = min(dur, s['end'] + tail_pad)\n",
        "\n",
        "        # 如果下一句起点更早，则把本句结尾卡在下一句起点之前\n",
        "        if i < len(sentences):\n",
        "            next_start = sentences[i].get('start', end)\n",
        "            end = min(end, max(0.0, next_start - guard_next))\n",
        "\n",
        "        # 防止出现负长度或 0 长度\n",
        "        if end <= start:\n",
        "            end = min(dur, start + 0.15)  # 保底 150ms\n",
        "\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms   = int(end * 1000)\n",
        "        chunk = audio[start_ms:end_ms]\n",
        "\n",
        "        # 仍沿用你原来的命名逻辑\n",
        "        t1, t2 = hhmmss(start).replace(\":\", \"-\"), hhmmss(end).replace(\":\", \"-\")\n",
        "        snippet = _safe_snippet(s['text'])\n",
        "        fname = f\"{i:03d}_{t1}_{t2}_{snippet}.{fmt}\"\n",
        "        fpath = str(Path(out_dir) / fname)\n",
        "\n",
        "        chunk.export(fpath, format=fmt)\n",
        "        saved_files.append(fpath)\n",
        "    return saved_files\n",
        "\n",
        "\n",
        "\n",
        "# ====================== 主流程 ======================\n",
        "print(\"=\" * 50)\n",
        "print(\"BASIC SPEECH RECOGNITION + SENTENCE SPLITTING + CLIP SAVING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "\n",
        "if USE_FILE_INPUT:\n",
        "    # 从音频“文件”开始\n",
        "    audio_source = INPUT_AUDIO\n",
        "else:\n",
        "    # 已有 16k 单声道 numpy 数组：audio_data\n",
        "    # audio_source = audio_data  # ← 解注释并确保变量存在\n",
        "    raise ValueError(\"请把 USE_FILE_INPUT 设为 True 或提供 audio_data 变量。\")\n",
        "\n",
        "# 转写\n",
        "result = transcribe_with_whisper(model, audio_source, language=None, task=\"transcribe\")\n",
        "\n",
        "# print(\"\\n📝 Transcription Results:\")\n",
        "# print(f\"Detected language: {result.get('language', 'unknown')}\")\n",
        "# print(f\"Transcript (raw): '{result.get('text','').strip()}'\")\n",
        "\n",
        "# 合并为“每句一段”\n",
        "sentences = merge_into_sentences(result, max_gap=2)\n",
        "\n",
        "print(\"\\n=== Formatted (one sentence per segment) ===\")\n",
        "for s in sentences:\n",
        "    print(f\"[{hhmmss(s['start'])}] Speaker_A: {s['text']}\")\n",
        "\n",
        "# 按句裁剪并保存\n",
        "saved = save_sentence_clips(INPUT_AUDIO, sentences, OUTPUT_DIR, fmt=\"wav\")\n",
        "print(f\"\\n✅ Saved {len(saved)} sentence clips to: {OUTPUT_DIR}\")\n",
        "print(\"Example files:\")\n",
        "print(\"\\n\".join(saved[:5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W68wmZ8kBC0G",
        "outputId": "6adba728-6988-4f28-fb1d-9a7b28cac74c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "BASIC SPEECH RECOGNITION + SENTENCE SPLITTING + CLIP SAVING\n",
            "==================================================\n",
            "🎙️ Starting transcribe with Whisper...\n",
            "   Language: auto-detect\n",
            "Detected language: French\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9105/9105 [01:51<00:00, 81.78frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Formatted (one sentence per segment) ===\n",
            "[00:00:00] Speaker_A: Comment les languages parlent?\n",
            "[00:00:02] Speaker_A: C 'est un peu le que vous me dites.\n",
            "[00:00:04] Speaker_A: Je suis très heureux que j 'ai eu une épargne de la dary, qui a été épargée à l 'Afghanistan.\n",
            "[00:00:10] Speaker_A: Je peux toujours réunir une nouvelle épargne de l 'origine, mais je suis en train de se réunir.\n",
            "[00:00:14] Speaker_A: Je suis le petit peu dégé de cette bandignana.\n",
            "[00:00:17] Speaker_A: Je veux dire que nous partageons le douleur aujourd 'hui que la catétrale de Notre Dame était comme une cadeau à la spécumène.\n",
            "[00:00:28] Speaker_A: Je suis un petit peu dégé à la Neussarlande, et je suis dans la même manière que la Maïa -Néthie, et la Maïa -Néthie, et la Nouvelle -État -South -Bend -Inihan.\n",
            "[00:00:33] Speaker_A: C 'est le seul que vous êtes un sens de inclusion dans notre pays.\n",
            "[00:00:37] Speaker_A: C 'est pas seulement dans la scepteur de l 'immigration, mais dans tous les assaises économiques, ce sont des de sécurité que nous sommes là -bas.\n",
            "[00:00:47] Speaker_A: Salut, tout le monde, tout le monde dégé.\n",
            "[00:00:49] Speaker_A: Oui, oui, tout le monde est un peu dégé.\n",
            "[00:00:55] Speaker_A: Tout le monde est un peu dégé.\n",
            "[00:00:55] Speaker_A: Tout le monde est un peu dégé.\n",
            "[00:00:57] Speaker_A: Tout le monde est un peu dégé.\n",
            "[00:00:58] Speaker_A: Les cops sont là pour ne pas guider de impressive.\n",
            "[00:01:02] Speaker_A: A la justoque est ce que j 'ai tenue.\n",
            "[00:01:03] Speaker_A: Purée aux portes d 'арищ rendent une ligure à l 'entre observe.\n",
            "[00:01:05] Speaker_A: Maintenant, je l 'ai jouée beaucoup ensemble dans la même domaine Amëla.\n",
            "[00:01:11] Speaker_A: Tu dois y entraîner ?\n",
            "[00:01:17] Speaker_A: Je vaisapprocher 1 20 uploading.\n",
            "[00:01:18] Speaker_A: Cette par collapses.\n",
            "[00:01:18] Speaker_A: Tu asught beer, que n 'èle pas des soldats ici avec les storedées.\n",
            "[00:01:26] Speaker_A: FOR TOTE, QUOI TETZERorean\n",
            "\n",
            "✅ Saved 23 sentence clips to: /content/video3/sentences_out\n",
            "Example files:\n",
            "/content/video3/sentences_out/001_00-00-00_00-00-01_Comment les languages parlent.wav\n",
            "/content/video3/sentences_out/002_00-00-02_00-00-03_C est un peu le que vous me dites.wav\n",
            "/content/video3/sentences_out/003_00-00-04_00-00-10_Je suis trs heureux que j ai eu une parg.wav\n",
            "/content/video3/sentences_out/004_00-00-10_00-00-14_Je peux toujours runir une nouvelle parg.wav\n",
            "/content/video3/sentences_out/005_00-00-14_00-00-17_Je suis le petit peu dg de cette bandign.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODnwRgCU7x82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import re\n",
        "import math\n",
        "import sys\n",
        "import whisper\n",
        "import torch\n",
        "\n",
        "# ========= 配置 =========\n",
        "INPUT_DIR = \"/content/video3/sentences_out\"\n",
        "OUTPUT_CSV = \"sentence_translate_results.csv\"\n",
        "OUTPUT_TXT = \"sentence_transcript_formatted.txt\"\n",
        "\n",
        "# 模型建议：CPU 用 \"base\" 或 \"small.en\"（纯英文）；有 GPU 可用 \"small\"/\"medium\"\n",
        "MODEL_SIZE = \"base\"\n",
        "\n",
        "# ========= 加载模型（自动选设备） =========\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "model = whisper.load_model(MODEL_SIZE, device=device)\n",
        "\n",
        "# ========= 工具函数 =========\n",
        "exts = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\"}\n",
        "\n",
        "def parse_time_from_name(name: str):\n",
        "    m = re.search(r\"\\[(\\d{2}):(\\d{2}):(\\d{2})\\]\", name)\n",
        "    if m:\n",
        "        h, mnt, s = map(int, m.groups())\n",
        "        return h*3600 + mnt*60 + s\n",
        "    m = re.search(r\"(\\d{2})[:\\-_](\\d{2})[:\\-_](\\d{2})\", name)\n",
        "    if m:\n",
        "        h, mnt, s = map(int, m.groups())\n",
        "        return h*3600 + mnt*60 + s\n",
        "    return None\n",
        "\n",
        "def parse_speaker_from_name(name: str):\n",
        "    m = re.search(r\"(speaker|spk)[\\s\\-_]*([A-Za-z0-9]+)\", name, flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        tag = m.group(2)\n",
        "        if len(tag) == 1 and tag.isalpha():\n",
        "            return f\"Speaker_{tag.upper()}\"\n",
        "        else:\n",
        "            return f\"Speaker_{tag}\"\n",
        "    return \"Speaker_1\"\n",
        "\n",
        "def sec_to_hhmmss(t: float):\n",
        "    t = max(0, int(math.floor(t + 1e-6)))\n",
        "    h = t // 3600\n",
        "    m = (t % 3600) // 60\n",
        "    s = t % 60\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# ========= 准备文件列表 & 断点续跑 =========\n",
        "clips = sorted([p for p in Path(INPUT_DIR).iterdir() if p.suffix.lower() in exts])\n",
        "\n",
        "already = set()\n",
        "if os.path.exists(OUTPUT_CSV):\n",
        "    try:\n",
        "        with open(OUTPUT_CSV, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for r in reader:\n",
        "                already.add(r[\"file\"])\n",
        "        print(f\"Will skip {len(already)} already-processed files from {OUTPUT_CSV}.\")\n",
        "    except Exception as e:\n",
        "        print(\"Warn: failed to read existing CSV for resume.\", e)\n",
        "\n",
        "csv_exists = os.path.exists(OUTPUT_CSV)\n",
        "csv_file = open(OUTPUT_CSV, \"a\", newline=\"\", encoding=\"utf-8\")\n",
        "writer = csv.DictWriter(csv_file, fieldnames=[\n",
        "    \"file\",\"start_time\",\"speaker\",\"language\",\"lang_confidence\",\"original_text\",\"english_text\"\n",
        "])\n",
        "if not csv_exists:\n",
        "    writer.writeheader()\n",
        "\n",
        "txt_mode = \"a\" if os.path.exists(OUTPUT_TXT) else \"w\"\n",
        "txt_file = open(OUTPUT_TXT, txt_mode, encoding=\"utf-8\")\n",
        "\n",
        "# ========= 主循环（更快的参数 + 即时落盘） =========\n",
        "current_time_seconds = 0.0\n",
        "processed_count = 0\n",
        "\n",
        "def fast_transcribe(path):\n",
        "    # 快速参数：不做温度回退、不开词级时间戳、独立片段\n",
        "    return model.transcribe(\n",
        "        str(path),\n",
        "        task=\"transcribe\",\n",
        "        language=None,              # 自动检测\n",
        "        temperature=0.0,            # 单温度，避免多次采样\n",
        "        best_of=1,\n",
        "        beam_size=1,\n",
        "        condition_on_previous_text=False,\n",
        "        fp16=(device==\"cuda\"),      # 只有 GPU 时才用 fp16\n",
        "        verbose=False,\n",
        "        word_timestamps=False,\n",
        "        no_speech_threshold=0.6,    # 稍微抬高静音阈值，跳过纯噪声\n",
        "        logprob_threshold=-1.0,     # 默认为 -1.0，必要时可放宽到 -1.2\n",
        "    )\n",
        "\n",
        "def fast_translate(path):\n",
        "    return model.transcribe(\n",
        "        str(path),\n",
        "        task=\"translate\",\n",
        "        language=None,\n",
        "        temperature=0.0,\n",
        "        best_of=1,\n",
        "        beam_size=1,\n",
        "        condition_on_previous_text=False,\n",
        "        fp16=(device==\"cuda\"),\n",
        "        verbose=False,\n",
        "        word_timestamps=False,\n",
        "        no_speech_threshold=0.6,\n",
        "        logprob_threshold=-1.0,\n",
        "    )\n",
        "\n",
        "try:\n",
        "    for i, clip in enumerate(clips, 1):\n",
        "        if clip.name in already:\n",
        "            continue\n",
        "\n",
        "        print(f\"[{i}/{len(clips)}] {clip.name}\")\n",
        "\n",
        "        start_sec_from_name = parse_time_from_name(clip.name)\n",
        "        speaker = parse_speaker_from_name(clip.name)\n",
        "\n",
        "        trans_result = fast_transcribe(clip)\n",
        "        original_text   = (trans_result.get(\"text\") or \"\").strip()\n",
        "        detected_lang   = trans_result.get(\"language\", \"unknown\")\n",
        "        lang_confidence = trans_result.get(\"language_probability\", None)\n",
        "\n",
        "        segs = trans_result.get(\"segments\") or []\n",
        "        clip_duration = max((s.get(\"end\", 0.0) or 0.0) for s in segs) if segs else 0.0\n",
        "\n",
        "        if start_sec_from_name is not None:\n",
        "            start_sec = float(start_sec_from_name)\n",
        "            current_time_seconds = start_sec + clip_duration\n",
        "        else:\n",
        "            start_sec = current_time_seconds\n",
        "            current_time_seconds += clip_duration\n",
        "\n",
        "        if detected_lang != \"en\":\n",
        "            english_text = (fast_translate(clip).get(\"text\") or \"\").strip()\n",
        "        else:\n",
        "            english_text = original_text\n",
        "\n",
        "        # —— 立刻写 CSV\n",
        "        writer.writerow({\n",
        "            \"file\": clip.name,\n",
        "            \"start_time\": sec_to_hhmmss(start_sec),\n",
        "            \"speaker\": speaker,\n",
        "            \"language\": detected_lang,\n",
        "            \"lang_confidence\": lang_confidence,\n",
        "            \"original_text\": original_text,\n",
        "            \"english_text\": english_text\n",
        "        })\n",
        "        csv_file.flush()\n",
        "\n",
        "        # —— 立刻写 TXT（两行：原文 + 需要时的翻译）\n",
        "        ts = sec_to_hhmmss(start_sec)\n",
        "        txt_file.write(f\"[{ts}] {speaker}: {original_text}\\n\")\n",
        "        if detected_lang != \"en\" and english_text and english_text != original_text:\n",
        "            txt_file.write(f\"[{ts}] {speaker}: [TRANSLATED] {english_text}\\n\")\n",
        "        txt_file.flush()\n",
        "\n",
        "        processed_count += 1\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⛔️ Interrupted by user. Partial results saved.\")\n",
        "finally:\n",
        "    csv_file.close()\n",
        "    txt_file.close()\n",
        "    print(f\"✅ Saved {processed_count} new rows. CSV: {OUTPUT_CSV} | TXT: {OUTPUT_TXT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us1KT-MN7x6C",
        "outputId": "46e1ac5e-9bfd-4ec6-e289-17226d86a741"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "[1/27] 001_00-00-00_00-00-01_Comment les languages parlent.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [00:01<00:00, 90.17frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2/27] 002_00-00-02_00-00-03_C est un peu le que vous me dites.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 171/171 [00:02<00:00, 84.47frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3/27] 003_00-00-04_00-00-10_Je suis trs heureux que j ai eu une parg.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 633/633 [00:02<00:00, 229.66frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/27] 004_00-00-10_00-00-14_Je peux toujours runir une nouvelle parg.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 417/417 [00:02<00:00, 185.30frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5/27] 005_00-00-14_00-00-17_Je suis le petit peu dg de cette bandign.wav\n",
            "Detected language: French\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 287/287 [00:02<00:00, 113.45frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: French\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 287/287 [00:03<00:00, 86.37frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6/27] 006_00-00-17_00-00-28_Je veux dire que nous partageons le doul.wav\n",
            "Detected language: French\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1097/1097 [00:03<00:00, 328.01frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: French\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1097/1097 [00:02<00:00, 381.91frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7/27] 007_00-00-27_00-00-30_Je suis le petit peu dg dans le maigre d.wav\n",
            "Detected language: Arabic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253/253 [00:02<00:00, 110.75frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Arabic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253/253 [00:02<00:00, 114.43frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8/27] 008_00-00-30_00-00-33_Je vis le petit peu dg dans le maigre de.wav\n",
            "Detected language: Hebrew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 305/305 [00:02<00:00, 112.56frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Hebrew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 305/305 [00:02<00:00, 144.66frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9/27] 009_00-00-33_00-00-37_Il faut que ce soit un sens d inclusion.wav\n",
            "Detected language: Spanish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [00:02<00:00, 183.02frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Spanish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [00:02<00:00, 148.05frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/27] 010_00-00-37_00-00-47_Ce n est pas seulement dans la scepture.wav\n",
            "Detected language: Spanish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 943/943 [00:02<00:00, 330.32frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Spanish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 943/943 [00:02<00:00, 379.67frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/27] 011_00-00-46_00-00-48_Salut petit peu dg je suis l.wav\n",
            "Detected language: Turkish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 197/197 [00:03<00:00, 59.99frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Turkish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 197/197 [00:02<00:00, 95.48frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/27] 012_00-00-49_00-00-51_Tu es le grand.wav\n",
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:02<00:00, 107.24frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:02<00:00, 84.15frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13/27] 013_00-00-52_00-00-55_et tout le monde est un peu renferment.wav\n",
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 321/321 [00:02<00:00, 150.53frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 321/321 [00:02<00:00, 158.28frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14/27] 014_00-00-55_00-00-59_Tant important de se coucher des fiets.wav\n",
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 401/401 [00:02<00:00, 153.32frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 401/401 [00:02<00:00, 183.60frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15/27] 015_00-00-59_00-01-00_Non non.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 43.88frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16/27] 016_00-01-00_00-01-03_De mme de carte de montagne je suis trs.wav\n",
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [00:02<00:00, 121.02frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Italian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [00:02<00:00, 139.42frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17/27] 017_00-01-03_00-01-04_Salut.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:01<00:00, 42.38frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18/27] 018_00-01-04_00-01-05_Fid -pot -digit -hester.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:02<00:00, 53.78frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19/27] 019_00-01-05_00-01-06_Regulment a m y va.wav\n",
            "Detected language: Swedish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 137/137 [00:02<00:00, 67.28frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Swedish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 137/137 [00:01<00:00, 68.56frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20/27] 020_00-01-07_00-01-08_Vous n avez pas l air de faire.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/94 [00:02<?, ?frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21/27] 021_00-01-09_00-01-11_Je vais vous faire un peu.wav\n",
            "Detected language: Swedish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 247/247 [00:02<00:00, 120.51frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Swedish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 247/247 [00:02<00:00, 116.38frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22/27] 022_00-01-11_00-01-13_Je vais vous faire un peu de l eau.wav\n",
            "Detected language: Hebrew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [00:02<00:00, 79.66frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Hebrew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167/167 [00:01<00:00, 84.46frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23/27] 023_00-01-14_00-01-17_On va faire un peu de l eau.wav\n",
            "Detected language: Portuguese\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [00:02<00:00, 162.62frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Portuguese\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [00:02<00:00, 172.01frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24/27] 024_00-01-17_00-01-21_On va faire un peu de l eau.wav\n",
            "Detected language: German\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [00:02<00:00, 163.35frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: German\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 399/399 [00:02<00:00, 158.10frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25/27] 025_00-01-21_00-01-25_On va faire un peu de l eau.wav\n",
            "Detected language: German\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 408/408 [00:02<00:00, 168.64frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: German\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 408/408 [00:02<00:00, 203.19frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26/27] 026_00-01-25_00-01-27_Je vais vous faire un peu de l eau.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [00:02<00:00, 55.33frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27/27] 027_00-01-28_00-01-29_C est trs bien.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:01<00:00, 66.35frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 27 new rows. CSV: sentence_translate_results.csv | TXT: sentence_transcript_formatted.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeAQeX1D7x3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUdk37297x1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4EjHEtD7xzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2YM3oIT7xxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ob2TADID7xuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}